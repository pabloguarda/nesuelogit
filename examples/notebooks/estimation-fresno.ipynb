{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import isuelogit as isl\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import geopandas as gpd\n",
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path management\n",
    "main_dir = str(Path(os.path.abspath('')).parents[1])\n",
    "os.chdir(main_dir)\n",
    "print('main dir:', main_dir)\n",
    "\n",
    "sys.path.append(os.path.join(main_dir, 'src'))\n",
    "\n",
    "isl.config.dirs['read_network_data'] = \"input/network-data/fresno/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pesuelogit.networks import read_OD\n",
    "from pesuelogit.etl import data_curation, add_period_id\n",
    "\n",
    "# Functions from internal modules\n",
    "from nesuelogit.models import compute_generated_trips, compute_generation_factors,  \\\n",
    "    create_tvodlulpe_model_fresno, create_tvgodlulpe_model_fresno, compute_benchmark_metrics\n",
    "from nesuelogit.etl import build_network, get_tensors_by_year\n",
    "from nesuelogit.visualizations import  plot_predictive_performance, plot_top_od_flows_periods, \\\n",
    "    plot_utility_parameters_periods, plot_rr_by_period, plot_rr_by_period_models, plot_total_trips_models, \\\n",
    "    plot_performance_functions, plot_flow_vs_traveltime, plot_flow_interaction_matrix, \\\n",
    "    plot_convergence_estimates, plot_parameters\n",
    "from nesuelogit.metrics import mse, mdape, r2_score, z2score\n",
    "from nesuelogit.utils import read_paths, load_k_shortest_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_LOSS_WEIGHTS = {'tvodlulpe': {'od': 0, 'traveltime': 1, 'flow': 1, 'equilibrium': 1},\n",
    "                 'tvgodlulpe': {'od': 0, 'traveltime': 1, 'flow': 1, 'equilibrium': 1}}\n",
    "_LR = {'tvodlulpe': {'learning': 1e-1, 'equilibrium': 5e-2},\n",
    "       'tvgodlulpe': {'learning': 1e1, 'equilibrium': 5e-2}}\n",
    "_EPOCHS = {'tvodlulpe':{'learning': 30, 'equilibrium': 0},\n",
    "           'tvgodlulpe':{'learning': 30, 'equilibrium': 0}}\n",
    "_EQUILIBRIUM_STAGE = {'tvodlulpe': False, 'tvgodlulpe': False}\n",
    "_RELATIVE_GAP = 1e-3\n",
    "_BATCH_SIZE = 1\n",
    "_HOURS = [6,7,8, 15,16,17]\n",
    "_DAYSOFWEEK = [0, 1,2,3, 4] # Monday:0, Sunday:6\n",
    "_LOSS_METRIC  = z2score\n",
    "_EVALUATION_METRIC = mdape\n",
    "\n",
    "_OPTIMIZERS = {'tvodlulpe':{'learning': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['tvodlulpe']['learning']),\n",
    "                            'equilibrium': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['tvodlulpe']['equilibrium'])\n",
    "                            },\n",
    "               'tvgodlulpe':{'learning': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['tvgodlulpe']['learning']),\n",
    "                            'equilibrium': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['tvgodlulpe']['equilibrium'])\n",
    "                            }\n",
    "              }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "_SEED = 2023\n",
    "np.random.seed(_SEED)\n",
    "random.seed(_SEED)\n",
    "tf.random.set_seed(_SEED)\n",
    "\n",
    "# To report global runtime\n",
    "t0_global = time.time()\n",
    "\n",
    "# Set timestamp to add in the filenames that are written in disk\n",
    "ts = datetime.now().strftime('%y%m%d%H%M%S')\n",
    "print('Timestamp:',ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Read nodes and link-specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "nodes_df = pd.read_csv('./input/network-data/fresno/nodes/fresno-nodes-gis-data.csv')\n",
    "\n",
    "links_df = pd.read_csv('./input/network-data/fresno/links/fresno-link-specific-data.csv',\n",
    "                       converters={\"link_key\": ast.literal_eval, \"pems_id\": ast.literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display network\n",
    "links_gdf = gpd.read_file('./input/network-data/fresno/gis/links/fresno-links-gis.shp').set_crs(\n",
    "        'EPSG:2228')\n",
    "ax = links_gdf.to_crs(epsg=3857).plot(figsize=(10, 10), alpha=0.5)\n",
    "ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Fresno network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = build_network(links_df=links_df, nodes_df=nodes_df, crs='epsg:4326', key= 'fresno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read OD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_OD(network=network, sparse=True)\n",
    "\n",
    "q_historic = np.repeat(network.q.flatten()[np.newaxis, :], 6, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Read paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_paths(network=network, update_incidence_matrices=True, filename = 'paths-fresno-k3.csv')\n",
    "read_paths(network=network, update_incidence_matrices=True, filename = 'paths-full-model-fresno.csv')\n",
    "\n",
    "#To generate K shortest paths and write in disk\n",
    "# _K = 3\n",
    "# load_k_shortest_paths(network=network, k=_K, theta = {'tt':-1}, update_incidence_matrices=True, block_output=False)\n",
    "# write_paths(network.paths, filepath=f'input/network-data/fresno/paths/paths-fresno-k{_K}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read spatiotemporal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = './input/network-data/fresno/links/spatiotemporal-data/'\n",
    "df = pd.concat([pd.read_csv(file) for file in glob.glob(folderpath + \"*link-data*\")], axis=0)\n",
    "\n",
    "df['link_key'] = pd.Categorical(df['link_key'].apply(ast.literal_eval), list(network.links_dict.keys()))\n",
    "df['period'] = pd.to_datetime(df['period'], format = '%Y-%m-%d-%H').dt.strftime('%Y-%m-%d-%H')\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "# Select data from Tuesday (1) to Thursday (3)\n",
    "df = df[df['date'].dt.dayofweek.isin(_DAYSOFWEEK)]\n",
    "# # Select data from one day only in 2019 and 2020\n",
    "# df = df[df['date'].isin([\"2019-10-01\", \"2020-10-06\"])]\n",
    "\n",
    "# # Select countdata from selected links\n",
    "# selected_links = [(290,169,'0'),(170,168,'0'),(337,692,'0'),(228,192,'0'),(191,171,'0'),(188,87,'0'), (171,290,'0'),(192,191,'0'),(87,228,'0'),(169,332,'0'),(631,635,'0'),(179,183,'0'), (641,86,'0'),(638,634,'0'),(170,207,'0'),(86,189,'0'),(580,142,'0'),(333,332,'0'), (99,43,'0'),(637,639,'0')]\n",
    "# df.loc[~df.link_key.isin(selected_links),'counts'] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add period id for timevarying estimation\n",
    "period_feature = 'hour'\n",
    "\n",
    "df = add_period_id(df, period_feature='hour')\n",
    "\n",
    "period_keys = df[[period_feature,'period_id']].drop_duplicates().reset_index().drop('index',axis =1).sort_values('hour')\n",
    "print(period_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Units in miles per hour\n",
    "df[['speed_ref_avg','speed_hist_avg','speed_max']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['speed_ref_avg']<=0,'speed_ref_avg'] = float('nan')\n",
    "\n",
    "df['tt_ff'] = np.where(df['link_type'] != 'LWRLK', 0,df['length']/df['speed_ref_avg'])\n",
    "df.loc[(df.link_type == \"LWRLK\") & (df.speed_ref_avg == 0),'tt_ff'] = float('nan')\n",
    "\n",
    "df['tt_avg'] = np.where(df['link_type'] != 'LWRLK', 0,df['length']/df['speed_hist_avg'])\n",
    "df.loc[(df.link_type == \"LWRLK\") & (df.speed_hist_avg == 0),'tt_avg'] = float('nan')\n",
    "\n",
    "tt_sd_adj = df.groupby(['period_id','link_key'])[['tt_avg']].std().reset_index().rename(columns = {'tt_avg': 'tt_sd_adj'})\n",
    "\n",
    "df = df.merge(tt_sd_adj, on = ['period_id','link_key'])\n",
    "\n",
    "df = data_curation(df)\n",
    "\n",
    "df['tt_sd'] = df['tt_sd_adj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Units of travel time features are converted from hours to minutes\n",
    "df['tt_sd'] = df['tt_sd']*60\n",
    "df['tt_avg'] = df['tt_avg']*60\n",
    "df['tt_ff'] = df['tt_ff']*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['speed_ref_avg','speed_hist_avg', 'tt_ff', 'tt_avg','tt_sd_adj']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = nodes_df.rename(columns ={'pop_tract':'population','stops_tract': 'bus_stops','median_inc':'income'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_generation = ['population','income', 'bus_stops']\n",
    "\n",
    "nodes_df = nodes_df[['key','type'] + features_generation]\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(nodes_df[features_generation])\n",
    "nodes_df[features_generation] = imp_mean.transform(nodes_df[features_generation])\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(nodes_df[features_generation].values)\n",
    "# scaler = preprocessing.MinMaxScaler().fit(nodes_df[features_generation].values)\n",
    "nodes_df[features_generation] = scaler.transform(nodes_df[features_generation].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_FEATURES_Z = ['tt_sd', 'median_inc', 'incidents', 'bus_stops', 'intersections']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_links = len(network.links)\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "df['year'] = df.date.dt.year\n",
    "X, Y = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('year == 2019')[['counts', 'tt_ff', 'tt_avg', 'tf_inrix', 'tt_sd']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('year == 2020')[['counts', 'tt_ff', 'tt_avg', 'tf_inrix', 'tt_sd']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set free flow travel times\n",
    "tt_ff_links = df.groupby('link_key')['tt_ff'].min()\n",
    "for link in network.links:\n",
    "    network.links_dict[link.key].performance_function.tf = float(tt_ff_links[tt_ff_links.index==link.key].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This correlation should be positive\n",
    "df[['counts','tt_avg']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check that there is a balanced amount of observations per date\n",
    "obs_date = df.groupby('date')['hour'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats by date\n",
    "df.groupby('date')[['speed_sd','speed_avg', 'counts']].mean().assign(total_obs = obs_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[_FEATURES_Z].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DTYPE = tf.float32\n",
    "\n",
    "# Hourly data DURING morning and afternoon peak hour windows (6 hour intervals) to estimate TVODLULPE\n",
    "XT, YT = get_tensors_by_year(df[df.hour.isin(_HOURS)], features_Z = _FEATURES_Z,\n",
    "                             links_keys=list(network.links_dict.keys()))\n",
    "\n",
    "# Split in training and test sets\n",
    "XT_train, XT_val, YT_train, YT_val = map(lambda x: tf.cast(x, dtype = _DTYPE), [XT[2019], XT[2020], YT[2019], YT[2020]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_periods = len(np.unique(XT_train[:, :, -1].numpy().flatten()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_dfs = {}\n",
    "val_results_dfs = {}\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Benchmark (TVODLULPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# To report runtime\n",
    "t0 = time.time()\n",
    "\n",
    "models['tvodlulpe'] = create_tvodlulpe_model_fresno(network = network, n_periods = n_periods, historic_q = q_historic,\n",
    "                                                    features_Z = _FEATURES_Z, dtype = _DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_results_dfs['tvodlulpe'], val_results_dfs['tvodlulpe'] = models['tvodlulpe'].fit(\n",
    "    XT_train, YT_train, XT_val, YT_val,\n",
    "    optimizers= _OPTIMIZERS['tvodlulpe'],\n",
    "    node_data=nodes_df,\n",
    "    batch_size=_BATCH_SIZE,\n",
    "    loss_weights=_LOSS_WEIGHTS['tvodlulpe'],\n",
    "    loss_metric= _LOSS_METRIC,\n",
    "    evaluation_metric = _EVALUATION_METRIC,\n",
    "    equilibrium_stage=_EQUILIBRIUM_STAGE['tvodlulpe'],\n",
    "    threshold_relative_gap=_RELATIVE_GAP,\n",
    "    epochs=_EPOCHS['tvodlulpe'])\n",
    "\n",
    "print(f'runtime: {time.time()-t0:0.1f} [s]')\n",
    "\n",
    "models['tvodlulpe'].save_weights(f\"output/models/{ts}_fresno_tvodlulpe.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = models['tvodlulpe'].compute_loss_metrics(\n",
    "    metrics={_EVALUATION_METRIC.__name__: _EVALUATION_METRIC, 'mse': mse, 'r2': r2_score},\n",
    "    X=XT_val, Y=YT_val).assign(dataset='validation')\n",
    "metrics_df = pd.concat([metrics_df,\n",
    "                        models['tvodlulpe'].compute_loss_metrics(\n",
    "                            metrics={_EVALUATION_METRIC.__name__: _EVALUATION_METRIC, 'mse': mse, 'r2': r2_score},\n",
    "                            X=XT_train, Y=YT_train).assign(dataset='training'),\n",
    "                        compute_benchmark_metrics(\n",
    "                            metrics={_EVALUATION_METRIC.__name__: _EVALUATION_METRIC, 'mse': mse, 'r2': r2_score},\n",
    "                            Y_ref=YT_train, Y=YT_val).assign(dataset='benchmark')\n",
    "                        ])\n",
    "\n",
    "with pd.option_context('display.float_format', '{:0.3g}'.format):\n",
    "    print(pd.pivot(metrics_df, index=['component', 'dataset'], columns=['metric'])['value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "flow_range = range(0,6000,100)\n",
    "sharey = False\n",
    "\n",
    "fig, axs = plot_performance_functions(model = models['tvodlulpe'],\n",
    "                                      network = network,\n",
    "                                      marginal = False,\n",
    "                                      #alpha=models['tvodlulpe'].performance_function.alpha,\n",
    "                                      #beta=models['tvodlulpe'].performance_function.beta,\n",
    "                                      alpha=0.15*np.ones(network.get_n_links()),\n",
    "                                      beta=4*np.ones(network.get_n_links()),\n",
    "                                      sharey = sharey,\n",
    "                                      flow_range = flow_range\n",
    "                                      # selected_links = np.random.choice(range(tntp_network.get_n_links()), 10, replace=False)\n",
    "                                      )\n",
    "\n",
    "# for ax in axs.reshape(-1):\n",
    "#     ax.set_xlim(xmin=-10)\n",
    "#     ax.set_ylim(ymin=-1)\n",
    "#     ax.legend(loc='upper left', title = 'link')\n",
    "\n",
    "plt.savefig('output/figures/results/fresno-comparison-all-link-performance-functions-tvodlulpe.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_links = np.random.choice(range(network.get_n_links()), 10, replace=False)\n",
    "\n",
    "plot_performance_functions(model=models['tvodlulpe'],\n",
    "                           network=network,\n",
    "                           marginal=True,\n",
    "                           # alpha=models['tvodlulpe'].performance_function.alpha,\n",
    "                           # beta=models['tvodlulpe'].performance_function.beta,\n",
    "                           alpha=0.15*np.ones(network.get_n_links()),\n",
    "                           beta=4*np.ones(network.get_n_links()),\n",
    "                           selected_links = selected_links,\n",
    "                           palette = sns.color_palette(\"hls\", len(selected_links)),\n",
    "                           sharey = sharey,\n",
    "                           flow_range = flow_range\n",
    "                           )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plot_flow_vs_traveltime(model = models['tvodlulpe'],\n",
    "                        observed_traveltime=models['tvodlulpe'].mask_observed_traveltime(YT_train[:, :, 0]),\n",
    "                        observed_flow= models['tvodlulpe'].mask_observed_flow(YT_train[:,:,1]),\n",
    "                        period_col = pd.DataFrame({'period': list(XT_train[:, :, -1].numpy().astype(int).flatten())})['period'].map(dict(zip(period_keys.period_id, period_keys.hour))).values.flatten(),\n",
    "                        hour_label=True,\n",
    "                        # scatter_kws={\"color\": sns.color_palette(\"deep\")[0], 's':4, 'alpha': 1}, line_kws={\"color\": \"black\"},\n",
    "                        all_metrics = False\n",
    "                        )\n",
    "\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.legend(loc='lower right', title = 'hour')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plot_predictive_performance(train_losses=train_results_dfs['tvodlulpe'], val_losses=val_results_dfs['tvodlulpe'],\n",
    "                            xticks_spacing=5, show_validation=True,\n",
    "                            curves=['equilibrium'],\n",
    "                            epochs_end_learning_stage=_EPOCHS['tvodlulpe']['learning'])\n",
    "\n",
    "plot_predictive_performance(train_losses=train_results_dfs['tvodlulpe'], val_losses=val_results_dfs['tvodlulpe'],\n",
    "                            xticks_spacing=5, show_validation=True,\n",
    "                            curves=['travel time', 'link flow'],\n",
    "                            epochs_end_learning_stage=_EPOCHS['tvodlulpe']['learning'], prefix_metric=_EVALUATION_METRIC.__name__,\n",
    "                            yaxis_label=f'{_EVALUATION_METRIC.__name__} (%)')\n",
    "\n",
    "plt.savefig(f'output/figures/results/fresno-{_EVALUATION_METRIC.__name__}-tvodlulpe.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_convergence_estimates(\n",
    "    estimates=train_results_dfs['tvodlulpe'].assign(\n",
    "        relative_gap=np.abs(train_results_dfs['tvodlulpe']['relative_gap']))[['epoch', 'relative_gap']],\n",
    "    xticks_spacing=5)\n",
    "\n",
    "#ax.set_ylim(ymin=1e-2, ymax = 5.5e-2)\n",
    "#ax.set_ylim(ymin=1e-2)\n",
    "ax.set_xlim(xmin=-0.5)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('relative gap (log scale)')\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.savefig('output/figures/results/fresno-relative-gap-tvodlulpe.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plot_convergence_estimates(estimates=train_results_dfs['tvodlulpe'][['epoch', 'alpha', 'beta']],\n",
    "                           xticks_spacing=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#sns.displot(plot_data, x=\"value\", hue=\"parameter\", multiple=\"stack\", kind=\"hist\", alpha=0.8, norm_hist=True)\n",
    "\n",
    "plot_data = pd.melt(pd.DataFrame({'alpha': models['tvodlulpe'].performance_function.alpha,\n",
    "                              'beta': models['tvodlulpe'].performance_function.beta}), var_name='parameter')\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (5,4))\n",
    "# sns.histplot(plot_data, x=\"value\", stat='density', hue=\"parameter\", alpha =0.8, ax = ax, binwidth = 0.5)\n",
    "\n",
    "try:\n",
    "    sns.displot(plot_data, x=\"value\", kind=\"hist\", stat='percent', common_norm=False, hue = \"parameter\", alpha=0.8, facet_kws=dict(sharey=False, sharex = False), binwidth = 0.5)\n",
    "    plt.savefig('output/figures/results/fresno-distribution-link-performance-parameters-tvodlulpe.png')\n",
    "    plt.show()\n",
    "except:\n",
    "    print('Distribution plot could not be shown')\n",
    "\n",
    "# Compute utility parameters over time (heatmap) and value of travel time reliability (lineplot)\n",
    "theta_df = plot_utility_parameters_periods(models['tvodlulpe'], period_keys = period_keys, period_feature='hour')\n",
    "\n",
    "print(theta_df)\n",
    "#print(theta_df.values)\n",
    "\n",
    "plot_rr_by_period(models['tvodlulpe'],period_keys, model_key = 'tvodlulpe', period_feature='hour')\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (5,4))\n",
    "sns.histplot(pd.DataFrame({'fixed_effect': np.array(models['tvodlulpe'].fixed_effect)}), stat='density', x=\"fixed_effect\", alpha=0.8, ax = ax, binwidth=0.5)\n",
    "plt.show()\n",
    "\n",
    "theta_df = plot_utility_parameters_periods(models['tvodlulpe'], period_keys=period_keys, period_feature='hour', plot = False).reset_index().\\\n",
    "    drop(['hour','index'], axis = 1).reset_index().rename(columns = {'index':'period'})\n",
    "\n",
    "# theta_df = pd.melt(theta_df.assign(rr = theta_df.apply(compute_rr, axis=1)), id_vars = 'period', var_name = 'parameter').assign(group = 'utility').\\\n",
    "#     replace({'tt': 'travel time', 'tt_sd': 'std. travel time', 'rr': 'reliability ratio', 's': 'intersections', 'bus_stops': 'bus stops', 'median_inc': 'income'})\n",
    "\n",
    "theta_df = pd.melt(theta_df, id_vars = 'period', var_name = 'parameter').assign(group = 'utility').\\\n",
    "    replace({'tt': 'travel time', 'tt_sd': 'std. travel time', 'rr': 'reliability ratio', 's': 'intersections', 'bus_stops': 'bus stops', 'median_inc': 'income'})\n",
    "\n",
    "theta_df['hour'] = theta_df['period'].map({v:period_keys[period_keys.period_id == k]['hour'].iloc[0] for k,v in models['tvodlulpe'].period_dict.items()})\n",
    "\n",
    "fig, axs = plot_parameters(df = theta_df, n_cols_legend = 3, figsize = (6,5.5), hour_label = True)\n",
    "\n",
    "plt.axhline(0, linestyle ='dashed', color = 'black')\n",
    "\n",
    "plt.savefig('output/figures/results/fresno-utility-periods-tvodlulpe.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot heatmap with flows of top od pairs\n",
    "plot_top_od_flows_periods(models['tvodlulpe'],\n",
    "                          historic_od= network.q.flatten(),\n",
    "                          period_keys = period_keys,\n",
    "                          period_feature='hour', top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"theta = \"\n",
    "      f\"{dict(zip(models['tvodlulpe'].utility.true_values.keys(), list(np.mean(models['tvodlulpe'].theta.numpy(), axis=0))))}\")\n",
    "\n",
    "print(f\"alpha = {np.mean(models['tvodlulpe'].performance_function.alpha): 0.2f}, \"\n",
    "          f\"beta  = {np.mean(models['tvodlulpe'].performance_function.beta): 0.2f}\")\n",
    "\n",
    "print(f\"Avg abs diff of observed and estimated OD: \"\n",
    "      f\"{np.mean(np.abs(models['tvodlulpe'].q - network.q.flatten())): 0.2f}\")\n",
    "\n",
    "print(f\"Avg observed OD: {np.mean(np.abs(network.q.flatten())): 0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVGODLULPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Total trips tvodlulpe pesuelogit:\n",
    "# Epoch 0: 6.6e+04 6.6e+04 6.6e+04 6.6e+04 6.6e+04 6.6e+04\n",
    "# Final epoch: 6.4e+04 6.6e+04 6.3e+04 7.8e+04 7.9e+04 7.9e+04\n",
    "# Growth factor captures the difference between the reference OD at epoch 0 and the estimated OD.\n",
    "growth_factor = 7.9/6.6\n",
    "#growth_factor = 1\n",
    "\n",
    "generation_factors = compute_generation_factors(period_column=XT_train[:, :, -1, None].numpy(),\n",
    "                                                              flow_column=YT_train[:,:,1, None].numpy(), reference_period=10)\n",
    "\n",
    "reference_g = growth_factor*generation_factors.values[:,np.newaxis]*compute_generated_trips(\n",
    "    q = q_historic, ods= network.ods, n_nodes = len(network.nodes))\n",
    "\n",
    "# generated_trips = compute_generated_trips(q = q_historic, ods= network.ods, n_nodes = len(network.nodes))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('\\ntvgodlulpe: Time varying route choice utility and trip generation, and link specific parameters for performance functions')\n",
    "\n",
    "# To report runtime\n",
    "t0 = time.time()\n",
    "\n",
    "models['tvgodlulpe'] = create_tvgodlulpe_model_fresno(network = network, n_periods = n_periods, features_Z = _FEATURES_Z,\n",
    "                                                      historic_g = reference_g, historic_q = q_historic)\n",
    "train_results_dfs['tvgodlulpe'], val_results_dfs['tvgodlulpe'] = models['tvgodlulpe'].fit(\n",
    "    XT_train, YT_train, XT_val, YT_val,\n",
    "    node_data=nodes_df,\n",
    "    optimizers= _OPTIMIZERS['tvgodlulpe'],\n",
    "    batch_size=_BATCH_SIZE,\n",
    "    loss_weights= _LOSS_WEIGHTS['tvgodlulpe'],\n",
    "    loss_metric=_LOSS_METRIC,\n",
    "    evaluation_metric = _EVALUATION_METRIC,\n",
    "    equilibrium_stage=_EQUILIBRIUM_STAGE['tvgodlulpe'],\n",
    "    threshold_relative_gap=_RELATIVE_GAP,\n",
    "    epochs=_EPOCHS['tvgodlulpe'])\n",
    "\n",
    "print(f'runtime: {time.time()-t0:0.1f} [s]')\n",
    "\n",
    "models['tvgodlulpe'].save_weights(f\"output/models/{ts}_fresno_tvgodlulpe.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = models['tvgodlulpe'].compute_loss_metrics(\n",
    "    metrics={_EVALUATION_METRIC.__name__: _EVALUATION_METRIC, 'mse': mse, 'r2': r2_score},\n",
    "    X=XT_val, Y=YT_val).assign(dataset='validation')\n",
    "metrics_df = pd.concat([metrics_df,\n",
    "                        models['tvgodlulpe'].compute_loss_metrics(\n",
    "                            metrics={_EVALUATION_METRIC.__name__: _EVALUATION_METRIC, 'mse': mse, 'r2': r2_score},\n",
    "                            X=XT_train, Y=YT_train).assign(dataset='training'),\n",
    "                        compute_benchmark_metrics(\n",
    "                            metrics={_EVALUATION_METRIC.__name__: _EVALUATION_METRIC, 'mse': mse, 'r2': r2_score},\n",
    "                            Y_ref=YT_train, Y=YT_val).assign(dataset='benchmark')\n",
    "                        ])\n",
    "\n",
    "with pd.option_context('display.float_format', '{:0.3g}'.format):\n",
    "    print(pd.pivot(metrics_df, index=['component', 'dataset'], columns=['metric'])['value'])\n",
    "print(f'runtime: {time.time()-t0:0.1f} [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_links = np.random.choice(range(network.get_n_links()), 20, replace=False)\n",
    "\n",
    "#weights_interaction = models['tvgodlulpe'].performance_function.weights[1].numpy()\n",
    "weights_interaction = models['tvgodlulpe'].performance_function.model.layers[0].kernel_matrix.numpy()\n",
    "initial_weights_interaction = models['tvgodlulpe'].performance_function.kernel_constraint.initial_values.numpy()\n",
    "# Plot sign of values in flow interaction matrix\n",
    "plot_flow_interaction_matrix(\n",
    "    flow_interaction_matrix=weights_interaction,\n",
    "    masking_matrix = initial_weights_interaction,\n",
    "    # flow_interaction_matrix=np.where(weights_interaction>0, 1, -1)*np.where(weights_interaction==0, 0, 1),\n",
    "    # masking_matrix = np.where(initial_weights_interaction>0, 1, -1)*np.where(initial_weights_interaction==0, 0, 1),\n",
    "    links_ids = selected_links + 1,\n",
    "    # vmin = -0.05, vmax = 0.05\n",
    "    vmin = -1, vmax = 1\n",
    ")\n",
    "\n",
    "plt.savefig('output/figures/results/fresno-kernel-link-performance-functions-tvgodlulpe.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f'Final weights interaction:\\n {weights_interaction}')\n",
    "print(f'\\nInitial weights interaction:\\n',initial_weights_interaction)\n",
    "\n",
    "# non_diagonal_mlp_weights = weights[~np.eye(weights.shape[0], dtype=bool)]\n",
    "# print(f\"Percentage of non-diagonal terms that are non-positive: {len(non_diagonal_mlp_weights[(non_diagonal_mlp_weights<=0)])/len(non_diagonal_mlp_weights):.2%}\")\n",
    "\n",
    "# non_zero_elements = weights_interaction[np.where(models['tvgodlulpe'].performance_function.kernel_constraint.initial_values.numpy()>0)]\n",
    "# print(f\"Percentage of non-zero terms that are positive: {len(non_zero_elements[(non_zero_elements>0)])/len(non_zero_elements):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of weight in interaction flow matrix. Elements that are set to zero by default are excluded from non-diagonal\n",
    "plot_data = pd.concat([pd.DataFrame({'value': tf.linalg.diag_part(weights_interaction).numpy().flatten(), 'parameter': 'diagonal'}),\n",
    "                                  pd.DataFrame({'value': weights_interaction[np.where(~np.eye(weights_interaction.shape[0],dtype=bool)*models['tvgodlulpe'].performance_function.kernel_constraint.adjacency_constraint_matrix)], 'parameter': 'non-diagonal'})])\n",
    "\n",
    "try:\n",
    "    sns.displot(data = plot_data, x=\"value\", kind=\"hist\", stat='percent', common_norm=False, hue = \"parameter\", alpha=0.8,\n",
    "                facet_kws=dict(sharey=False, sharex = False), binwidth = 0.5) # , col=\"parameter\"\n",
    "    plt.savefig('output/figures/results/fresno-distribution-link-performance-parameters-tvgodlulpe.png')\n",
    "    plt.show()\n",
    "except:\n",
    "    print('Distribution plot could not be shown')\n",
    "\n",
    "plot_data['value_abs'] = plot_data.value.abs()\n",
    "\n",
    "print(plot_data.groupby('parameter')[['value', 'value_abs']].mean())\n",
    "print(plot_data.groupby('parameter')[['value']].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight of polynomial\n",
    "print(f\"polynomial weights {tf.reduce_mean(models['tvgodlulpe'].performance_function.polynomial_layer.poly_weights,0).numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "flow_range = range(0,6000,100)\n",
    "sharey = False\n",
    "\n",
    "plot_performance_functions(model = models['tvgodlulpe'],\n",
    "                           network = network,\n",
    "                           marginal = False,\n",
    "                           alpha= 0.15, #models['tvodlulpe'].performance_function.alpha,\n",
    "                           beta= 4, #models['tvodlulpe'].performance_function.beta,\n",
    "                           sharey = sharey,\n",
    "                           flow_range = flow_range\n",
    "                           )\n",
    "\n",
    "plt.savefig('output/figures/results/fresno-comparison-all-link-performance-functions-tvgodlulpe.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "selected_links = np.random.choice(range(network.get_n_links()), 10, replace=False)\n",
    "\n",
    "plot_performance_functions(model = models['tvgodlulpe'],\n",
    "                           network = network,\n",
    "                           marginal = True,\n",
    "                           selected_links = selected_links,\n",
    "                           alpha=0.15*np.ones(network.get_n_links()),\n",
    "                           beta=4*np.ones(network.get_n_links()),\n",
    "                           palette = sns.color_palette(\"hls\", len(selected_links)),\n",
    "                           sharey = sharey,\n",
    "                           flow_range = flow_range\n",
    "                           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plot_flow_vs_traveltime(model = models['tvgodlulpe'],\n",
    "                        observed_traveltime=models['tvgodlulpe'].mask_observed_traveltime(YT_train[:, :, 0]),\n",
    "                        observed_flow= models['tvgodlulpe'].mask_observed_flow(YT_train[:,:,1]),\n",
    "                        period_col = pd.DataFrame({'period': list(XT_train[:, :, -1].numpy().astype(int).flatten())})['period'].map(dict(zip(period_keys.period_id, period_keys.hour))).values.flatten(),\n",
    "                        hour_label=True,\n",
    "                        all_metrics = False\n",
    "                        )\n",
    "\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.legend(loc='lower right', title = 'hour')\n",
    "\n",
    "plt.savefig('output/figures/results/fresno-scatter-flow-traveltime-tvgodlulpe.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictive_performance(train_losses=train_results_dfs['tvgodlulpe'], val_losses=val_results_dfs['tvgodlulpe'],\n",
    "                            xticks_spacing=5, show_validation=True,\n",
    "                            curves=['equilibrium'],\n",
    "                            epochs_end_learning_stage=_EPOCHS['tvgodlulpe']['learning'])\n",
    "\n",
    "plot_predictive_performance(train_losses=train_results_dfs['tvgodlulpe'], val_losses=val_results_dfs['tvgodlulpe'],\n",
    "                            xticks_spacing=5, show_validation=True,\n",
    "                            curves=['travel time', 'link flow'],\n",
    "                            epochs_end_learning_stage=_EPOCHS['tvgodlulpe']['learning'], prefix_metric=_EVALUATION_METRIC.__name__,\n",
    "                            yaxis_label=f'{_EVALUATION_METRIC.__name__} (%)')\n",
    "\n",
    "plt.savefig(f'output/figures/results/fresno-{_EVALUATION_METRIC.__name__}-tvgodlulpe.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_convergence_estimates(\n",
    "    estimates=train_results_dfs['tvgodlulpe'].assign(\n",
    "        relative_gap=np.abs(train_results_dfs['tvgodlulpe']['relative_gap']))[['epoch', 'relative_gap']],\n",
    "    xticks_spacing=5)\n",
    "\n",
    "#ax.set_ylim(ymin=1e-2)\n",
    "# ax.set_ylim(ymin=1e-2, ymax = 5.5e-2)\n",
    "ax.set_xlim(xmin=-0.5)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('relative gap (log scale)')\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.savefig('output/figures/results/fresno-relative-gap-tvgodlulpe.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute utility parameters over time (heatmap) and value of travel time reliability (lineplot)\n",
    "theta_df = plot_utility_parameters_periods(models['tvgodlulpe'], period_keys = period_keys, period_feature='hour')\n",
    "#print(theta_df.values)\n",
    "\n",
    "plot_rr_by_period(models['tvgodlulpe'], period_keys, model_key = 'tvgodlulpe', period_feature='hour')\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (5,4))\n",
    "sns.histplot(pd.DataFrame({'fixed_effect': np.array(models['tvodlulpe'].fixed_effect)}), stat='density', x=\"fixed_effect\", alpha=0.8, ax = ax, binwidth=0.5)\n",
    "plt.show()\n",
    "\n",
    "# Plot parameters by period\n",
    "theta_df = plot_utility_parameters_periods(models['tvgodlulpe'], period_keys=period_keys, period_feature='hour', plot = False).reset_index().\\\n",
    "    drop(['hour','index'], axis = 1).reset_index().rename(columns = {'index':'period'})\n",
    "\n",
    "# theta_df = pd.melt(theta_df.assign(rr = theta_df.apply(compute_rr, axis=1)), id_vars = 'period', var_name = 'parameter').assign(group = 'utility')\n",
    "\n",
    "theta_df = pd.melt(theta_df, id_vars = 'period', var_name = 'parameter').assign(group = 'utility')\n",
    "\n",
    "kappa_df = pd.concat([pd.DataFrame({'period': [period], 'parameter': [feature], 'value': [models['tvgodlulpe'].kappa[period, i].numpy()]}) for period in range(models['tvgodlulpe'].kappa.shape[0]) for i, feature in enumerate(models['tvgodlulpe'].generation.features)]).assign(group = 'generation')\n",
    "\n",
    "parameters_df = pd.concat([theta_df, kappa_df]).\\\n",
    "    replace({'tt': 'travel time', 'tt_sd': 'std. travel time', 's': 'intersections', 'bus_stops': 'bus stops', 'median_inc': 'income', 'rr': 'reliability ratio'})\n",
    "\n",
    "parameters_df['hour'] = parameters_df['period'].map({v:period_keys[period_keys.period_id == k]['hour'].iloc[0] for k,v in models['tvgodlulpe'].period_dict.items()})\n",
    "\n",
    "fig, ax = plot_parameters(df = parameters_df[parameters_df.group == 'utility'], n_cols_legend = 3, figsize = (6,5.5), hour_label = True)\n",
    "\n",
    "plt.axhline(0, linestyle ='dashed', color = 'black')\n",
    "\n",
    "plt.savefig('output/figures/results/fresno-utility-periods-tvgodlulpe.png')\n",
    "\n",
    "plot_parameters(df = parameters_df[parameters_df.group == 'generation'], n_cols_legend = 3, figsize = (5.5,5.5), hour_label = True)\n",
    "\n",
    "plt.axhline(0, linestyle ='dashed', color = 'black')\n",
    "\n",
    "plt.savefig('output/figures/results/fresno-generation-periods-tvgodlulpe.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Theta:', models['tvgodlulpe'].theta.numpy().T)\n",
    "print('Kappa:', models['tvgodlulpe'].kappa.numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot heatmap with flows of top od pairs\n",
    "plot_top_od_flows_periods(models['tvgodlulpe'],\n",
    "                          historic_od= network.q.flatten(),\n",
    "                          period_keys = period_keys,\n",
    "                          period_feature='hour', top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"theta = \"\n",
    "      f\"{dict(zip(models['tvgodlulpe'].utility.true_values.keys(), list(np.mean(models['tvgodlulpe'].theta.numpy(), axis=0))))}\")\n",
    "print(f\"kappa= \"\n",
    "      f\"{dict(zip(models['tvgodlulpe'].generation.features, list(np.mean(models['tvgodlulpe'].kappa.numpy(), axis=0))))}\")\n",
    "\n",
    "if models['tvgodlulpe'].performance_function.type == 'bpr':\n",
    "    print(f\"alpha = {np.mean(models['tvgodlulpe'].performance_function.alpha): 0.2f}, \"\n",
    "          f\"beta  = {np.mean(models['tvgodlulpe'].performance_function.beta): 0.2f}\")\n",
    "\n",
    "print(f\"Avg abs diff of observed and estimated OD: \"\n",
    "      f\"{np.mean(np.abs(models['tvgodlulpe'].q - network.q.flatten())): 0.2f}\")\n",
    "\n",
    "print(f\"Avg observed OD: {np.mean(np.abs(network.q.flatten())): 0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Write estimation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_results_df, val_results_df \\\n",
    "    = map(lambda x: pd.concat([results.assign(model = model)[['model'] + list(results.columns)]\n",
    "                               for model, results in x.items()],axis = 0), [train_results_dfs, val_results_dfs])\n",
    "\n",
    "train_filename = f\"{ts}_train_results_{network.key}.csv\"\n",
    "val_filename = f\"{ts}_validation_results_{network.key}.csv\"\n",
    "train_results_df.to_csv(f\"./output/tables/{train_filename}\")\n",
    "print(f'File {train_filename} was written')\n",
    "val_results_df.to_csv(f\"./output/tables/{val_filename}\")\n",
    "print(f'File {val_filename} was written')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of parameter estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### All models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'parameter': [], 'model': []})\n",
    "\n",
    "for model_key, model in models.items():\n",
    "    model_results = {**dict(zip(['tt'] + _FEATURES_Z, list(np.mean(model.theta.numpy(), axis=0)))),\n",
    "                     **{'rr': float(model.get_parameters_estimates().eval('tt_sd/tt').iloc[0]),\n",
    "                        'fixed_effect_mean': np.mean(model.fixed_effect),\n",
    "                        'fixed_effect_std': np.std(model.fixed_effect),\n",
    "                        'od_mean': np.mean(model.q),\n",
    "                        'od_std': np.std(model.q)\n",
    "                        }}\n",
    "\n",
    "    if model.performance_function.type == 'bpr':\n",
    "        model_results = {**model_results, **{'alpha_mean': np.mean(model.performance_function.alpha),\n",
    "                                             'alpha_std': np.std(model.performance_function.alpha),\n",
    "                                             'beta_mean': np.mean(model.performance_function.beta),\n",
    "                                             'beta_std': np.std(model.performance_function.beta)}}\n",
    "\n",
    "    model_results = pd.DataFrame({'parameter': model_results.keys(), 'values': model_results.values()}). \\\n",
    "        assign(model=model_key)\n",
    "\n",
    "    results = pd.concat([results, model_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.pivot_table(index = ['parameter'], columns = 'model', values = 'values', sort=False).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### TVGODLULPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Stats by period\n",
    "model = models['tvgodlulpe']\n",
    "\n",
    "with pd.option_context('display.float_format', '{:0.4f}'.format):\n",
    "    print('theta:', pd.DataFrame(model.theta.numpy().T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.4f}'.format):\n",
    "    print('kappa:', pd.DataFrame(model.kappa.numpy().T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# with pd.option_context('display.float_format', '{:0.1f}'.format):\n",
    "with pd.option_context('display.float_format', '{:0.4f}'.format):\n",
    "    print('OD matrix', pd.DataFrame({'od_mean': np.mean(model.q,axis = 1), 'od_std': np.std(model.q, axis = 1), 'od_total':np.sum(model.q,axis = 1)}).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of models goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_losses = pd.DataFrame({})\n",
    "loss_columns = ['loss_flow', 'loss_traveltime', 'loss_equilibrium', 'loss_total']\n",
    "\n",
    "for model_key, model in models.items():\n",
    "    results_losses_model = model.split_results(train_results_dfs[model_key])[1].assign(model=model_key)\n",
    "    results_losses_model = results_losses_model[results_losses_model.epoch == _EPOCHS[model_key]['learning']].iloc[[0]]\n",
    "    results_losses = pd.concat([results_losses, results_losses_model])\n",
    "\n",
    "results_losses[loss_columns] = (results_losses[loss_columns] - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.4f}'.format):\n",
    "    print(results_losses[['model'] + list(results_losses.columns)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of convergence toward true rr across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_estimates = {}\n",
    "train_losses = {}\n",
    "\n",
    "for model_key, model in models.items():\n",
    "    train_estimates[model_key], train_losses[model_key] = model.split_results(results=train_results_dfs[model_key])\n",
    "\n",
    "    train_estimates[model_key]['model'] = model_key\n",
    "\n",
    "train_estimates_df = pd.concat(train_estimates.values())\n",
    "\n",
    "train_estimates_df['rr'] = train_estimates_df['tt_sd'] / train_estimates_df['tt']\n",
    "\n",
    "estimates = train_estimates_df[['epoch', 'model', 'rr']].reset_index().drop('index', axis=1)\n",
    "#estimates = estimates[estimates.epoch != 0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "g = sns.lineplot(data=estimates, x='epoch', hue='model', y='rr')\n",
    "\n",
    "# ax.hlines(y=compute_rr(models.popitem().true_values), xmin=estimates['epoch'].min(), xmax=estimates['epoch'].max(), linestyle='--', label = 'truth')\n",
    "\n",
    "ax.set_ylabel('reliability ratio')\n",
    "\n",
    "ax.set_xticks(np.arange(estimates['epoch'].min(), estimates['epoch'].max() + 2, 5))\n",
    "\n",
    "#ax.set_yscale('log')\n",
    "#plt.ylim(ymin=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of reliability ratio by hour for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reliability_ratios = plot_rr_by_period_models(models, period_keys, period_feature='hour', join = True)\n",
    "\n",
    "plt.savefig('output/figures/results/fresno-reliability-ratios-periods.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(reliability_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.4f}'.format):\n",
    "    print(reliability_ratios[reliability_ratios.model == 'tvgodlulpe'][['hour','rr']].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reliability_ratios.groupby('model')[['rr']].mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of total trips by hour for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trips = plot_total_trips_models(models = models, period_feature = 'hour', period_keys = period_keys,\n",
    "                                      historic_od = network.q.flatten(), join = True)\n",
    "\n",
    "plt.savefig('output/figures/results/fresno-total-trips-periods.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(total_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trips.groupby('model')[['total_trips']].mean().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trips.groupby('model')[['total_trips']].sum().round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Global runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'runtime: {time.time()-t0_global:0.1f} [s]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nesuelogit",
   "language": "python",
   "name": "nesuelogit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
