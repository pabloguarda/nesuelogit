{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import isuelogit as isl\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pesuelogit.visualizations import plot_heatmap_demands\n",
    "from pesuelogit.models import compute_rr\n",
    "from pesuelogit.networks import build_tntp_network\n",
    "from pesuelogit.etl import get_design_tensor, add_period_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Path management\n",
    "main_dir = str(Path(os.path.abspath('')).parents[1])\n",
    "os.chdir(main_dir)\n",
    "print('main dir:', main_dir)\n",
    "\n",
    "sys.path.append(os.path.join(main_dir, 'src'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Internal modules\n",
    "from nesuelogit.models import ODParameters, UtilityParameters, BPR, create_model_tntp, create_bpr, create_mlp_tntp, \\\n",
    "    create_tvodlulpe_model_tntp, create_tvgodlulpe_model_tntp, train_val_split_by_links, train_kfold, compute_generated_trips, \\\n",
    "    compute_generation_factors, compute_benchmark_metrics\n",
    "from nesuelogit.visualizations import plot_predictive_performance, plot_metrics_kfold, \\\n",
    "    plot_top_od_flows_periods, plot_utility_parameters_periods, plot_flow_vs_traveltime, plot_performance_functions, \\\n",
    "    plot_annotate_r2, plot_flow_interaction_matrix, plot_parameters_kfold, plot_parameters, plot_convergence_estimates, \\\n",
    "    compute_total_trips_models\n",
    "from nesuelogit.metrics import mse, mape, r2_score, z2score\n",
    "from nesuelogit.utils import load_k_shortest_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "_SEED = 2023\n",
    "np.random.seed(_SEED)\n",
    "random.seed(_SEED)\n",
    "tf.random.set_seed(_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To report global runtime\n",
    "t0_global = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'SiouxFalls'\n",
    "network = build_tntp_network(network_name=network_name, folderpath=os.getcwd() + \"/input/tntp/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read OD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load true demand matrix\n",
    "Q = isl.reader.read_tntp_od(network_name=network_name, folderpath=os.getcwd() + \"/input/tntp/\")\n",
    "network.load_OD(Q=Q)\n",
    "\n",
    "Q_true = [network.OD.Q_true, 0.8*network.OD.Q_true]\n",
    "q_true = tf.stack([network.OD.q_true.flatten(), 0.8*network.OD.q_true.flatten()], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_historic = [isl.factory.random_disturbance_Q(i.copy(), sd=np.mean(i) * 0.1) for i in Q_true]\n",
    "q_historic = [isl.networks.denseQ(i.copy()).flatten() for i in Q_historic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_k_shortest_paths(network=network, k=3, update_incidence_matrices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthethic data which was generated under the assumption of path sets of size 2.\n",
    "df = pd.read_csv(\n",
    "    main_dir + '/input/network-data/' + network.key + '/links/' + network.key + '-link-data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic node data\n",
    "node_data = pd.DataFrame({'key': [node.key for node in network.nodes],\n",
    "                          'income': np.random.rand(len(network.nodes)),\n",
    "                          'population': np.random.rand(len(network.nodes))\n",
    "                          })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exogenous features in utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_FEATURES_Z = ['tt_sd', 's']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timepoints = len(df.timepoint.unique())\n",
    "n_links = len(network.links)\n",
    "\n",
    "# Add free flow travel times\n",
    "df['tt_ff'] = np.tile([link.bpr.tf for link in network.links], n_timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_feature = 'hour'\n",
    "df = df.rename(columns = {'period': 'hour'})\n",
    "df = add_period_id(df, period_feature=period_feature)\n",
    "\n",
    "period_keys = df[[period_feature, 'period_id']].drop_duplicates().reset_index().drop('index', axis=1).sort_values(period_feature)\n",
    "print(period_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_design_tensor(Z=df[_FEATURES_Z + ['period_id']], n_links=n_links, n_timepoints=n_timepoints )\n",
    "Y = get_design_tensor(y=df[['traveltime', 'counts']], n_links=n_links, n_timepoints=n_timepoints)\n",
    "\n",
    "# df_T = df[df.hour.isin([0, 5])]\n",
    "df_T = df\n",
    "XT = get_design_tensor(Z=df_T[_FEATURES_Z + ['period_id']], n_links=n_links, n_timepoints=n_timepoints )\n",
    "YT = get_design_tensor(y=df_T[['traveltime', 'counts']], n_links=n_links, n_timepoints=n_timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DTYPE = tf.float32\n",
    "\n",
    "X, XT, Y, YT = [tf.cast(i, _DTYPE) for i in [X, XT, Y, YT]]\n",
    "\n",
    "Y_train, Y_val = train_val_split_by_links(Y.numpy(), val_size=0)\n",
    "YT_train, YT_val = train_val_split_by_links(YT.numpy(), val_size=0)\n",
    "\n",
    "Y_val, YT_val = None, None\n",
    "\n",
    "X_train, X_val = X, X\n",
    "X_train, X_val, Y_train, Y_val = [tf.cast(i, _DTYPE) if i is not None else None for i in [X_train, X_val, Y_train, Y_val]]\n",
    "\n",
    "XT_train, XT_val = XT, XT\n",
    "XT_train, XT_val, YT_train, YT_val = [tf.cast(i, _DTYPE) if i is not None else None for i in [XT_train, XT_val, YT_train, YT_val]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume no access to historic OD matrix, thus, od weight is zero\n",
    "_LOSS_WEIGHTS = {'od': 0, 'theta': 0, 'traveltime': 1, 'flow': 1, 'equilibrium': 1,\n",
    "                 # 'regularizer_od': 0, 'regularizer_kernel': 0, 'regularizer_utility_ods': 0\n",
    "                 }\n",
    "_EQUILIBRIUM_STAGE = True\n",
    "_ALTERNATING_OPTIMIZATION = False\n",
    "_LR = {'learning': 1e-2, 'equilibrium': 1e-2}\n",
    "_BATCH_SIZE = 1\n",
    "_EPOCHS = {'learning': 30, 'equilibrium': 30}\n",
    "# _BATCH_SIZE = None\n",
    "# _EPOCHS = {'learning': 2, 'equilibrium': 1}\n",
    "_EPOCHS_PRINT_INTERVAL = {'learning': 1, 'equilibrium': 1}\n",
    "_XTICKS_SPACING = 5\n",
    "_RELATIVE_GAP = 1e-5\n",
    "_LOSS_METRIC = z2score\n",
    "_OPTIMIZERS = {'learning': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['learning']),\n",
    "               'equilibrium': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['equilibrium'])\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "train_results_dfs = {}\n",
    "val_results_dfs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Equilibrium (SUELOGIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gradient based SUELOGIT')\n",
    "\n",
    "# Note: Here we assume we know the True OD matrix and the scale of the second period is obtained from the link flow data. Otherwise,\n",
    "# the link flows and travel times obtained at equilibrium will not necessarily match the observed data.\n",
    "\n",
    "# To report runtime\n",
    "t0 = time.time()\n",
    "\n",
    "n_periods = len(np.unique(XT_train[:, :, -1].numpy().flatten()))\n",
    "\n",
    "generation_factors = compute_generation_factors(period_column=X[:, :, -1, None].numpy(),\n",
    "                                                flow_column=Y[:, :, 1, None].numpy(), reference_period=0)\n",
    "# generation_factors = np.array([1,1])\n",
    "\n",
    "generated_trips = compute_generated_trips(q=isl.networks.denseQ(Q).flatten()[np.newaxis, :],\n",
    "                                          ods=network.ods, n_nodes = len(network.nodes))\n",
    "\n",
    "suelogit, _ = create_model_tntp(network = network,\n",
    "                                model_key = 'suelogit',\n",
    "                                n_periods= n_periods,\n",
    "                                performance_function = BPR(keys=['alpha', 'beta'],\n",
    "                                                           initial_values={'alpha': 0.15, 'beta': 4},\n",
    "                                                           trainables={'alpha': True, 'beta':True},\n",
    "                                                           capacities = [link.bpr.k for link in network.links],\n",
    "                                                           free_flow_traveltimes =[link.bpr.tf for link in network.links],\n",
    "                                                           dtype = _DTYPE\n",
    "                                                           ),\n",
    "                                utility_parameters = UtilityParameters(features_Y=['tt'],\n",
    "                                                                       features_Z=_FEATURES_Z,\n",
    "                                                                       initial_values={'tt': -1, 'tt_sd': -1.3, 's': -3, 'psc_factor': 0,\n",
    "                                                                                       'fixed_effect': np.zeros_like(network.links)},\n",
    "                                                                       time_varying=True,\n",
    "                                                                       dtype=_DTYPE\n",
    "                                                                       ),\n",
    "                                od_parameters = ODParameters(key='od',\n",
    "                                                             initial_values= generation_factors.values[:,np.newaxis]*network.q.flatten(),\n",
    "                                                             ods=network.ods,\n",
    "                                                             n_nodes = len(network.nodes),\n",
    "                                                             n_periods=n_periods,\n",
    "                                                             time_varying=True,\n",
    "                                                             trainable=False),\n",
    "                                generation = False,\n",
    "                                historic_g= generation_factors.values[:,np.newaxis]*generated_trips)\n",
    "\n",
    "train_results_dfs['suelogit'], val_results_dfs['suelogit'] = suelogit.compute_equilibrium(\n",
    "    XT_train,\n",
    "    node_data=node_data,\n",
    "    # loss_metric=_LOSS_METRIC,\n",
    "    optimizer=_OPTIMIZERS['equilibrium'],\n",
    "    batch_size=_BATCH_SIZE,\n",
    "    loss_weights={'equilibrium': 1},\n",
    "    threshold_relative_gap=_RELATIVE_GAP,\n",
    "    pretrain_link_flows = True,\n",
    "    epochs_print_interval=_EPOCHS_PRINT_INTERVAL,\n",
    "    epochs=_EPOCHS['learning'] + _EPOCHS['equilibrium'])\n",
    "\n",
    "print(f'\\nruntime: {time.time() - t0:0.1f} [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_predictive_performance(train_losses=train_results_dfs['suelogit'], val_losses=val_results_dfs['suelogit'],\n",
    "                            xticks_spacing=10, curves=['equilibrium'])\n",
    "\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-relative-mse-suelogit.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "train_results_estimates, train_results_losses = suelogit.split_results(results=train_results_dfs['suelogit'])\n",
    "val_results_estimates, val_results_losses = suelogit.split_results(results=val_results_dfs['suelogit'])\n",
    "\n",
    "fig, ax = plot_convergence_estimates(\n",
    "    estimates=train_results_losses.assign(\n",
    "        relative_gap=np.abs(train_results_losses['relative_gap']))[['epoch', 'relative_gap']],\n",
    "    xticks_spacing=10)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('relative gap (log scale)')\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-relative-gap-suelogit.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_flow_vs_traveltime(model = suelogit,\n",
    "                        observed_traveltime=Y[:, :, 0],\n",
    "                        observed_flow= Y[:,:,1],\n",
    "                        period_col = X[:,:,-1].numpy().astype(int).flatten(),\n",
    "                        # scatter_kws={\"color\": sns.color_palette(\"deep\")[0], 's':4, 'alpha': 1}, line_kws={\"color\": \"black\"},\n",
    "                        all_metrics = False,\n",
    "                        only_observed = True,\n",
    "                        )\n",
    "\n",
    "ax.legend(loc='lower right', title = 'period')\n",
    "\n",
    "ax.set_xlim(xmin=-1e-2)\n",
    "ax.set_ylim(ymin=-1e-2)\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-scatter-flow-traveltime.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_flow_vs_traveltime(model = suelogit,\n",
    "                        observed_traveltime=Y[:, :, 0],\n",
    "                        observed_flow= Y[:,:,1],\n",
    "                        period_col = X[:,:,-1].numpy().astype(int).flatten(),\n",
    "                        # scatter_kws={\"color\": sns.color_palette(\"deep\")[0], 's':4, 'alpha': 1}, line_kws={\"color\": \"black\"},\n",
    "                        all_metrics = False\n",
    "                        )\n",
    "\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.set_xlim(xmin=-1e-2)\n",
    "    ax.set_ylim(ymin=-1e-2)\n",
    "    ax.legend(loc='lower right', title = 'period')\n",
    "\n",
    "# axs[1,1].set_xlim(xmin=-1)\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-scatter-flow-traveltime-suelogit.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Benchmark (TVODLULPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\ntvodlulpe: Time specific utility and OD, link performance parameters, no historic OD')\n",
    "\n",
    "n_periods = len(np.unique(XT_train[:, :, -1].numpy().flatten()))\n",
    "\n",
    "generated_trips = compute_generated_trips(q=tf.stack(q_historic), ods=network.ods,\n",
    "                                          n_nodes = len(network.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "\n",
    "models['tvodlulpe'] = create_tvodlulpe_model_tntp(network = network, n_periods = n_periods,\n",
    "                                                  historic_g = generated_trips, historic_q = q_historic, features_Z=_FEATURES_Z)\n",
    "\n",
    "train_results_dfs['tvodlulpe'], val_results_dfs['tvodlulpe'] = models['tvodlulpe'].fit(\n",
    "    XT_train, YT_train, XT_val, YT_val,\n",
    "    optimizers= {'learning': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['learning']),\n",
    "                 'equilibrium': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['equilibrium'])},\n",
    "    node_data=node_data,\n",
    "    batch_size=_BATCH_SIZE,\n",
    "    loss_weights=_LOSS_WEIGHTS,\n",
    "    loss_metric= _LOSS_METRIC,\n",
    "    equilibrium_stage=_EQUILIBRIUM_STAGE,\n",
    "    pretrain_link_flows = True,\n",
    "    threshold_relative_gap=_RELATIVE_GAP,\n",
    "    epochs_print_interval=_EPOCHS_PRINT_INTERVAL,\n",
    "    epochs=_EPOCHS)\n",
    "\n",
    "print(f'\\nruntime: {time.time() - t0:0.1f} [s]')\n",
    "\n",
    "models['tvodlulpe'].save_weights(models['tvodlulpe']._filepath_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_range = range(0, 20000, 100)\n",
    "sharey = False\n",
    "\n",
    "fig, axs = plot_performance_functions(model = models['tvodlulpe'],\n",
    "                                      network = network,\n",
    "                                      marginal = False,\n",
    "                                      alpha=0.15*np.ones(network.get_n_links()),\n",
    "                                      beta=4*np.ones(network.get_n_links()),\n",
    "                                      sharey = sharey,\n",
    "                                      flow_range = flow_range\n",
    "                                      # selected_links = np.random.choice(range(network.get_n_links()), 10, replace=False)\n",
    "                                      )\n",
    "\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.set_xlim(xmin=-10)\n",
    "    ax.set_ylim(ymin=-1)\n",
    "    ax.legend(loc='upper left', title = 'link')\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-comparison-all-link-performance-functions-tvodlulpe.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "selected_links = np.random.choice(range(network.get_n_links()), 10, replace=False)\n",
    "\n",
    "plot_performance_functions(model=models['tvodlulpe'],\n",
    "                           network=network,\n",
    "                           marginal=True,\n",
    "                           alpha=0.15*np.ones(network.get_n_links()),\n",
    "                           beta=4*np.ones(network.get_n_links()),\n",
    "                           selected_links = selected_links,\n",
    "                           palette = sns.color_palette(\"hls\", len(selected_links)),\n",
    "                           sharey = sharey,\n",
    "                           flow_range = flow_range\n",
    "                           )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_flow_vs_traveltime(model = models['tvodlulpe'],\n",
    "                                   observed_traveltime=Y[:, :, 0],\n",
    "                                   observed_flow= Y[:,:,1],\n",
    "                                   period_col = X[:,:,-1].numpy().astype(int).flatten(),\n",
    "                                   # scatter_kws={\"color\": sns.color_palette(\"deep\")[0], 's':4, 'alpha': 1}, line_kws={\"color\": \"black\"},\n",
    "                                   all_metrics = False\n",
    "                                   )\n",
    "\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.set_xlim(xmin=-1e-2)\n",
    "    ax.set_ylim(ymin=-1e-2)\n",
    "    ax.legend(loc='lower right', title = 'period')\n",
    "\n",
    "axs[1,1].set_xlim(xmin=-1)\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-scatter-flow-traveltime-tvodlulpe.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictive_performance(train_losses=train_results_dfs['tvodlulpe'],\n",
    "                            val_losses=val_results_dfs['tvodlulpe'],\n",
    "                            # curves = ['link flow', 'travel time'],\n",
    "                            xticks_spacing=_XTICKS_SPACING, show_validation=False,\n",
    "                            epochs_end_learning_stage=_EPOCHS['learning'])\n",
    "\n",
    "plot_predictive_performance(train_losses=train_results_dfs['tvodlulpe'],\n",
    "                            val_losses=val_results_dfs['tvodlulpe'],\n",
    "                            curves = ['link flow', 'travel time'],\n",
    "                            xticks_spacing=_XTICKS_SPACING, show_validation=False,\n",
    "                            epochs_end_learning_stage=_EPOCHS['learning'])\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-relative-mse-tvodlulpe.png')\n",
    "\n",
    "plot_predictive_performance(train_losses=train_results_dfs['tvodlulpe'],\n",
    "                            val_losses=val_results_dfs['tvodlulpe'],\n",
    "                            curves = ['equilibrium'],\n",
    "                            xticks_spacing=_XTICKS_SPACING, show_validation=False,\n",
    "                            epochs_end_learning_stage=_EPOCHS['learning'])\n",
    "\n",
    "plot_predictive_performance(train_losses=train_results_dfs['tvodlulpe'],\n",
    "                            val_losses=val_results_dfs['tvodlulpe'],\n",
    "                            xticks_spacing=_XTICKS_SPACING, show_validation=False,\n",
    "                            # curves = ['link flow', 'travel time'],\n",
    "                            epochs_end_learning_stage=_EPOCHS['learning'], prefix_metric='mape',\n",
    "                            yaxis_label='mape')\n",
    "\n",
    "plot_predictive_performance(train_losses=train_results_dfs['tvodlulpe'],\n",
    "                            val_losses=val_results_dfs['tvodlulpe'],\n",
    "                            xticks_spacing=_XTICKS_SPACING, show_validation=False,\n",
    "                            curves = ['link flow', 'travel time'],\n",
    "                            epochs_end_learning_stage=_EPOCHS['learning'], prefix_metric='mape',\n",
    "                            yaxis_label='mape')\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-mape-tvodlulpe.png')\n",
    "\n",
    "plot_predictive_performance(train_losses=train_results_dfs['tvodlulpe'],\n",
    "                            val_losses=val_results_dfs['tvodlulpe'],\n",
    "                            xticks_spacing=_XTICKS_SPACING, show_validation=False,\n",
    "                            curves = ['equilibrium'],\n",
    "                            epochs_end_learning_stage=_EPOCHS['learning'], prefix_metric='mape',\n",
    "                            yaxis_label='mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_convergence_estimates(\n",
    "    estimates=train_results_dfs['tvodlulpe'].assign(\n",
    "        relative_gap=np.abs(train_results_dfs['tvodlulpe']['relative_gap']))[['epoch', 'relative_gap']],\n",
    "    xticks_spacing=_XTICKS_SPACING)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('relative gap (log scale)')\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-relative-gap-tvodlulpe.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_convergence_estimates(estimates=train_results_dfs['tvodlulpe'][['epoch', 'alpha', 'beta']],\n",
    "                           xticks_spacing=_XTICKS_SPACING,\n",
    "                           true_values=models['tvodlulpe'].performance_function.parameters.true_values,\n",
    "                           )\n",
    "\n",
    "plt.show()\n",
    "plot_data = pd.melt(pd.DataFrame({'alpha': models['tvodlulpe'].performance_function.alpha,\n",
    "                                  'beta': models['tvodlulpe'].performance_function.beta}), var_name='parameter')\n",
    "\n",
    "#sns.displot(plot_data, x=\"value\", hue=\"parameter\", multiple=\"stack\", kind=\"hist\", alpha=0.8, norm_hist=True)\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (5,4))\n",
    "# sns.histplot(plot_data, x=\"value\", stat='density', hue=\"parameter\", ax = ax)\n",
    "\n",
    "# sns.displot(plot_data, x=\"value\", col=\"parameter\", kind=\"hist\", hue = \"parameter\", alpha=0.8, facet_kws=dict(sharey=False, sharex = False), binwidth = 0.25)\n",
    "try:\n",
    "    sns.displot(plot_data, x=\"value\", kind=\"hist\", stat='percent', common_norm=False, hue = \"parameter\", alpha=0.8, facet_kws=dict(sharey=False, sharex = False), binwidth = 0.25)\n",
    "    plt.savefig('output/figures/experiments/siouxfalls-distribution-link-performance-parameters-tvodlulpe.png')\n",
    "    plt.show()\n",
    "except:\n",
    "    print('Distribution plot could not be shown')\n",
    "\n",
    "print(plot_data.groupby('parameter')['value'].mean())\n",
    "\n",
    "fig, ax = plot_convergence_estimates(estimates=train_results_dfs['tvodlulpe']. \\\n",
    "                           assign(rr=train_results_dfs['tvodlulpe']['tt_sd'] / train_results_dfs['tvodlulpe']['tt'])[['epoch', 'rr']],\n",
    "                           true_values={'rr': models['tvodlulpe'].utility.true_values['tt_sd']/models['tvodlulpe'].utility.true_values['tt']},\n",
    "                           xticks_spacing=_XTICKS_SPACING)\n",
    "# ax.legend(loc = 'lower right')\n",
    "ax.get_legend().remove()\n",
    "ax.set_ylabel(\"reliability ratio\")\n",
    "plt.show()\n",
    "\n",
    "# Utility by period\n",
    "\n",
    "theta_df = plot_utility_parameters_periods(models['tvodlulpe'], period_keys=period_keys, period_feature='hour', plot = False).reset_index().drop(['hour','index'], axis = 1).reset_index().rename(columns = {'index':'period'})\n",
    "\n",
    "# theta_df = pd.melt(theta_df.assign(rr = theta_df.apply(compute_rr, axis=1)), id_vars = 'period', var_name = 'parameter').assign(group = 'utility').replace({'tt': 'travel time', 'tt_sd': 'std. travel time', 's': 'intersections', 'rr': 'reliability ratio'})\n",
    "\n",
    "theta_df = pd.melt(theta_df, id_vars = 'period', var_name = 'parameter').assign(group = 'utility').replace({'tt': 'travel time', 'tt_sd': 'std. travel time', 's': 'intersections'})\n",
    "\n",
    "fig, ax = plot_parameters(df = theta_df, n_cols_legend = 3, figsize = (6,5.5))\n",
    "\n",
    "plt.axhline(0, linestyle ='dashed', color = 'black')\n",
    "\n",
    "plt.savefig(f'output/figures/experiments/siouxfalls-utility-periods-tvodlulpe.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(theta_df)\n",
    "\n",
    "# Compute utility parameters over time (heatmap) and value of travel time reliability (lineplot)\n",
    "# theta_df = plot_utility_parameters_periods(models['tvodlulpe'], period_keys=period_keys, period_feature='hour', plot = False)\n",
    "#\n",
    "# rr_df = theta_df.apply(compute_rr, axis=1).reset_index().rename(columns={'index': period_feature, 0: 'rr'})\n",
    "#\n",
    "# sns.lineplot(data=rr_df, x=period_feature, y=\"rr\")\n",
    "#\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap with flows of top od pairs\n",
    "_ = plot_top_od_flows_periods(models['tvodlulpe'], period_keys=period_keys, period_feature=period_feature, top_k=20,\n",
    "                          historic_od=network.q.flatten())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot heatmaps with OD matrix\n",
    "\n",
    "estimated_Q = models['tvodlulpe'].Q.numpy()\n",
    "plot_data = pd.DataFrame()\n",
    "\n",
    "for period in range(estimated_Q.shape[0]):\n",
    "    print(f'period {period}\\n')\n",
    "    Qs = {'true': Q_true[period], 'estimated': estimated_Q[period]}  # 'historic': Q_historic,\n",
    "\n",
    "    rho_val, p = sp.stats.pearsonr(Qs[\"true\"].flatten(), Qs[\"estimated\"].flatten())\n",
    "    print(f'correlation: {rho_val}')\n",
    "\n",
    "    plot_heatmap_demands(Qs=Qs, vmin=np.min(Q_true[0]), vmax=np.max(Q_true[0]), subplots_dims=(1, len(Qs.keys())),\n",
    "                         figsize=(4*len(Qs.keys()), 4))\n",
    "    plt.show()\n",
    "\n",
    "    plot_data = pd.concat([plot_data, pd.DataFrame({'true': Qs['true'].flatten(), 'estimated':Qs['estimated'].flatten(),\n",
    "                                                    'period': period})])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4), tight_layout=True)\n",
    "sns.scatterplot(data=plot_data, x='true', y='estimated', hue = 'period', ax = ax)\n",
    "plot_annotate_r2(ax=ax, x=plot_data['true'], y=plot_data['estimated'], intercept = False, r2 = True, rho = True)\n",
    "ax.set_xlabel('true number of trips')\n",
    "ax.set_ylabel('estimated number of trips')\n",
    "ax.legend(loc='lower right', title = 'period')\n",
    "ax.set_xlim(xmin=-1e-2)\n",
    "ax.set_ylim(ymin=-1e-2)\n",
    "\n",
    "plt.savefig(f'output/figures/experiments/siouxfalls-scatter-ode-tvodlulpe.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"theta = \"\n",
    "      f\"{dict(zip(models['tvodlulpe'].utility.true_values.keys(), list(np.mean(models['tvodlulpe'].theta.numpy(), axis=0))))}\")\n",
    "\n",
    "if models['tvodlulpe'].performance_function.type == 'bpr':\n",
    "    print(f\"alpha = {np.mean(models['tvodlulpe'].performance_function.alpha): 0.2f}, \"\n",
    "          f\"beta  = {np.mean(models['tvodlulpe'].performance_function.beta): 0.2f}\")\n",
    "\n",
    "print(f\"Avg abs diff of observed and estimated OD: \"\n",
    "      f\"{np.mean(np.abs(models['tvodlulpe'].q - network.q.flatten())): 0.2f}\")\n",
    "\n",
    "print(f\"Avg observed OD: {np.mean(np.abs(network.q.flatten())): 0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = models['tvodlulpe'].compute_loss_metrics(metrics={'mape': mape, 'mse': mse, 'r2': r2_score},\n",
    "                                                      X=XT_train, Y=YT_train).assign(dataset='training')\n",
    "\n",
    "if YT_val is not None:\n",
    "    metrics_df = pd.concat([metrics_df,\n",
    "                            models['tvodlulpe'].compute_loss_metrics(metrics={'mape': mape, 'mse': mse, 'r2': r2_score},\n",
    "                                                                     X=XT_val, Y=YT_val).assign(dataset='validation'),\n",
    "                            compute_benchmark_metrics(metrics={'mape': mape, 'mse': mse, 'r2': r2_score}, Y_ref=YT_train,\n",
    "                                                      Y=YT_val).assign(\n",
    "                                dataset='benchmark')\n",
    "                            ])\n",
    "\n",
    "with pd.option_context('display.float_format', '{:0.2g}'.format):\n",
    "    print(pd.pivot(metrics_df, index=['component', 'dataset'], columns=['metric'])['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) TVGODLULPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_periods = len(np.unique(XT_train[:, :, -1].numpy().flatten()))\n",
    "\n",
    "generated_trips = compute_generated_trips(q=tf.stack(q_historic), ods=network.ods, n_nodes = len(network.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['tvgodlulpe'] = create_tvgodlulpe_model_tntp(network = network, n_periods=n_periods,\n",
    "                                                    historic_g = generated_trips, historic_q = q_historic, features_Z=_FEATURES_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "train_results_dfs['tvgodlulpe'], val_results_dfs['tvgodlulpe'] = models['tvgodlulpe'].fit(\n",
    "    XT_train, YT_train, XT_val, YT_val,\n",
    "    optimizers= {'learning': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['learning']),\n",
    "                 'equilibrium': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['equilibrium'])},\n",
    "    node_data=node_data,\n",
    "    batch_size=_BATCH_SIZE,\n",
    "    loss_weights=_LOSS_WEIGHTS,\n",
    "    loss_metric= _LOSS_METRIC,\n",
    "    equilibrium_stage=_EQUILIBRIUM_STAGE,\n",
    "    pretrain_link_flows = True,\n",
    "    threshold_relative_gap=_RELATIVE_GAP,\n",
    "    epochs_print_interval=_EPOCHS_PRINT_INTERVAL,\n",
    "    epochs=_EPOCHS\n",
    ")\n",
    "\n",
    "print(f'\\nruntime: {time.time() - t0:0.1f} [s]')\n",
    "\n",
    "models['tvgodlulpe'].save_weights(models['tvgodlulpe']._filepath_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_flow_vs_traveltime(model = models['tvgodlulpe'],\n",
    "                        observed_traveltime=Y[:, :, 0],\n",
    "                        observed_flow= Y[:,:,1],\n",
    "                        period_col = X[:,:,-1].numpy().astype(int).flatten(),\n",
    "                        # scatter_kws={\"color\": sns.color_palette(\"deep\")[0], 's':4, 'alpha': 1}, line_kws={\"color\": \"black\"},\n",
    "                        all_metrics = False\n",
    "                        )\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.set_xlim(xmin=-1e-2)\n",
    "    ax.set_ylim(ymin=-1e-2)\n",
    "    ax.legend(loc='lower right', title = 'period')\n",
    "\n",
    "axs[1,1].set_xlim(xmin=-1)\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-scatter-flow-traveltime-tvgodlulpe.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_range = range(0, 20000, 100)\n",
    "sharey = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_performance_functions(model = models['tvgodlulpe'],\n",
    "                                      network = network,\n",
    "                                      marginal = False,\n",
    "                                      alpha=0.15*np.ones(network.get_n_links()),\n",
    "                                      beta=4*np.ones(network.get_n_links()),\n",
    "                                      sharey = sharey,\n",
    "                                      flow_range = flow_range\n",
    "                                      )\n",
    "\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.set_xlim(xmin=-10)\n",
    "    ax.set_ylim(ymin=-1)\n",
    "    ax.legend(loc='upper left', title = 'link')\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-comparison-all-link-performance-functions-tvgodlulpe.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plot_performance_functions(model = models['tvgodlulpe'],\n",
    "#                                network = network,\n",
    "#                                marginal = True,\n",
    "#                                alpha=models['tvgodlulpe'].performance_function.polynomial_layer.alpha_prior*np.ones(network.get_n_links()),\n",
    "#                                beta=models['tvgodlulpe'].performance_function.polynomial_layer.beta_prior*np.ones(network.get_n_links()),\n",
    "#                                # alpha=0.15*np.ones(network.get_n_links()),\n",
    "#                                # beta=4*np.ones(network.get_n_links()),\n",
    "#                                sharey = sharey,\n",
    "#                                flow_range = flow_range\n",
    "#                                # selected_links = np.random.choice(range(network.get_n_links()), 10, replace=False)\n",
    "#                                )\n",
    "#\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_links = np.random.choice(range(network.get_n_links()), 10, replace=False)\n",
    "\n",
    "# Plot with bpr used the priors of the BPR parameters used to pretrain the MLP\n",
    "\n",
    "plot_performance_functions(model=models['tvgodlulpe'],\n",
    "                           network=network,\n",
    "                           marginal=False,\n",
    "                           alpha=0.15*np.ones(network.get_n_links()),\n",
    "                           beta=4*np.ones(network.get_n_links()),\n",
    "                           selected_links = selected_links,\n",
    "                           palette = sns.color_palette(\"hls\", len(selected_links)),\n",
    "                           sharey = sharey,\n",
    "                           flow_range = flow_range\n",
    "                           )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plot_performance_functions(model=models['tvgodlulpe'],\n",
    "                           network=network,\n",
    "                           marginal=False,\n",
    "                           alpha=0.15*np.ones(network.get_n_links()),\n",
    "                           beta=4*np.ones(network.get_n_links()),\n",
    "                           selected_links = selected_links,\n",
    "                           palette = sns.color_palette(\"hls\", len(selected_links)),\n",
    "                           sharey = sharey,\n",
    "                           flow_range = flow_range\n",
    "                           )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Marginal increases show that function are still monotonically increasing\n",
    "plot_performance_functions(model=models['tvgodlulpe'],\n",
    "                           network=network,\n",
    "                           marginal=True,\n",
    "                           alpha=0.15*np.ones(network.get_n_links()),\n",
    "                           beta=4*np.ones(network.get_n_links()),\n",
    "                           selected_links = selected_links,\n",
    "                           palette = sns.color_palette(\"hls\", len(selected_links)),\n",
    "                           sharey = sharey,\n",
    "                           flow_range = flow_range\n",
    "                           )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments assume no link flow interactions and that all parameters mapping flow to travel time have the same value.\n",
    "# With this approach, the parameter becomes almost equal to alpha = 0.15.\n",
    "# weights = models['tvgodlulpe'].performance_function.weights[1].numpy()\n",
    "if models['tvgodlulpe'].performance_function.kernel_constraint.homogenous:\n",
    "    weights_interaction = models['tvgodlulpe'].performance_function.model.layers[0].parameter.numpy()\n",
    "else:\n",
    "    # weights_interaction = models['tvgodlulpe'].performance_function.weights[-1].numpy()\n",
    "    weights_interaction = models['tvgodlulpe'].performance_function.model.layers[0].kernel_matrix.numpy()\n",
    "\n",
    "initial_weights = models['tvgodlulpe'].performance_function.kernel_constraint.initial_values.numpy()\n",
    "\n",
    "plot_flow_interaction_matrix(\n",
    "    flow_interaction_matrix=weights_interaction,\n",
    "    masking_matrix = initial_weights,\n",
    "    #flow_interaction_matrix= np.where(weights_interaction>0, 1, -1)*np.where(weights_interaction==0, 0, 1),\n",
    "    #masking_matrix = np.where(initial_weights>0, 1, -1)*np.where(initial_weights==0, 0, 1),\n",
    "    # vmin = -0.2, vmax = 0.2\n",
    "    vmin = -1, vmax = 1\n",
    ")\n",
    "plt.savefig('output/figures/experiments/siouxfalls-kernel-link-performance-functions-tvgodlulpe.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f'Final weights:\\n {weights_interaction}')\n",
    "print(f'\\nInitial weights:\\n',initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of weight in interaction flow matrix. Elements that are set to zero by default are excluded from non-diagonal\n",
    "plot_data = pd.concat([pd.DataFrame({'value': tf.linalg.diag_part(weights_interaction).numpy().flatten(), 'parameter': 'diagonal'}),\n",
    "                                  pd.DataFrame({'value': weights_interaction[np.where(~np.eye(weights_interaction.shape[0],dtype=bool)*models['tvgodlulpe'].performance_function.kernel_constraint.adjacency_constraint_matrix)], 'parameter': 'non-diagonal'})])\n",
    "\n",
    "plot_data['value_abs'] = plot_data.value.abs()\n",
    "\n",
    "# sns.displot(data = plot_data, x=\"value\", col=\"type\", kind=\"hist\", hue = \"type\", alpha=0.8, facet_kws=dict(sharey=False, sharex = False))\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (5,4))\n",
    "# sns.histplot(plot_data, x=\"value\", stat='density', hue=\"parameter\", alpha = 0.8, multiple=\"stack\", ax = ax)\n",
    "try:\n",
    "    sns.displot(data = plot_data, x=\"value\", kind=\"hist\", stat='percent', common_norm=False, hue = \"parameter\", alpha=0.8,\n",
    "                facet_kws=dict(sharey=False, sharex = False), binwidth = 0.25)\n",
    "    plt.xlim(-0.5, 10)\n",
    "    plt.savefig('output/figures/experiments/siouxfalls-distribution-link-performance-parameters-tvgodlulpe.png')\n",
    "    plt.show()\n",
    "except:\n",
    "    print('Distribution plot could not be shown')\n",
    "print(plot_data.groupby('parameter')[['value', 'value_abs']].mean())\n",
    "print(plot_data.groupby('parameter')[['value']].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight of polynomial\n",
    "print(f\"polynomial weights {tf.reduce_mean(models['tvgodlulpe'].performance_function.polynomial_layer.poly_weights,0).numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictive_performance(train_losses=train_results_dfs['tvgodlulpe'],\n",
    "                            val_losses=val_results_dfs['tvgodlulpe'], show_validation=False,\n",
    "                            xticks_spacing=_XTICKS_SPACING,\n",
    "                            epochs_end_learning_stage=_EPOCHS['learning'])\n",
    "\n",
    "plot_predictive_performance(train_losses=train_results_dfs['tvgodlulpe'],\n",
    "                            # val_losses=val_results_dfs['tvgodlulpe'],\n",
    "                            curves = ['link flow', 'travel time'],\n",
    "                            xticks_spacing=_XTICKS_SPACING, show_validation=False,\n",
    "                            epochs_end_learning_stage=_EPOCHS['learning'])\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-relative-mse-tvgodlulpe.png')\n",
    "\n",
    "plot_predictive_performance(train_losses=train_results_dfs['tvgodlulpe'],\n",
    "                            val_losses=val_results_dfs['tvgodlulpe'], show_validation=False,\n",
    "                            xticks_spacing=_XTICKS_SPACING,\n",
    "                            curves=['equilibrium'],\n",
    "                            epochs_end_learning_stage=_EPOCHS['learning'])\n",
    "\n",
    "\n",
    "plot_predictive_performance(train_losses=train_results_dfs['tvgodlulpe'][train_results_dfs['tvgodlulpe'].epoch>0],\n",
    "                                      val_losses=val_results_dfs['tvgodlulpe'], show_validation=False,\n",
    "                                      xticks_spacing=_XTICKS_SPACING,\n",
    "                                      # curves = ['link flow', 'travel time'],\n",
    "                                      epochs_end_learning_stage=_EPOCHS['learning'], prefix_metric='mape',\n",
    "                                      yaxis_label='mape')\n",
    "\n",
    "plot_predictive_performance(train_losses=train_results_dfs['tvgodlulpe'][train_results_dfs['tvgodlulpe'].epoch>0],\n",
    "                                      val_losses=val_results_dfs['tvgodlulpe'], show_validation=False,\n",
    "                                      xticks_spacing=_XTICKS_SPACING,\n",
    "                                      curves = ['link flow', 'travel time'],\n",
    "                                      epochs_end_learning_stage=_EPOCHS['learning'], prefix_metric='mape',\n",
    "                                      yaxis_label='mape')\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-mape-tvgodlulpe.png')\n",
    "\n",
    "plot_predictive_performance(train_losses=train_results_dfs['tvgodlulpe'][train_results_dfs['tvgodlulpe'].epoch>0],\n",
    "                                      val_losses=val_results_dfs['tvgodlulpe'], show_validation=False,\n",
    "                                      xticks_spacing=_XTICKS_SPACING,\n",
    "                                      curves=['equilibrium'],\n",
    "                                      epochs_end_learning_stage=_EPOCHS['learning'], prefix_metric='mape',\n",
    "                                      yaxis_label='mape')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_convergence_estimates(\n",
    "    estimates=train_results_dfs['tvgodlulpe'].assign(\n",
    "        relative_gap=np.abs(train_results_dfs['tvgodlulpe']['relative_gap']))[['epoch', 'relative_gap']],\n",
    "    xticks_spacing=_XTICKS_SPACING)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('relative gap (log scale)')\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-relative-gap-tvgodlulpe.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plot_convergence_estimates(estimates=train_results_dfs['tvgodlulpe']. \\\n",
    "                                     assign(rr=train_results_dfs['tvgodlulpe']['tt_sd'] / train_results_dfs['tvgodlulpe']['tt'])[['epoch', 'rr']],\n",
    "                                     true_values={'rr': models['tvgodlulpe'].utility.true_values['tt_sd']/models['tvgodlulpe'].utility.true_values['tt']},\n",
    "                                     xticks_spacing=_XTICKS_SPACING)\n",
    "# ax.legend(loc = 'lower right')\n",
    "ax.get_legend().remove()\n",
    "ax.set_ylabel(\"reliability ratio\")\n",
    "plt.show()\n",
    "\n",
    "# Utility by period\n",
    "theta_df = plot_utility_parameters_periods(models['tvgodlulpe'], period_keys=period_keys, period_feature='hour', plot = False).reset_index().drop(['hour','index'], axis = 1).reset_index().rename(columns = {'index':'period'})\n",
    "\n",
    "# theta_df = pd.melt(theta_df.assign(rr = theta_df.apply(compute_rr, axis=1)), id_vars = 'period', var_name = 'parameter').assign(group = 'utility').\\\n",
    "#     replace({'tt': 'travel time', 'tt_sd': 'std. travel time', 's': 'intersections', 'rr': 'reliability ratio'})\n",
    "\n",
    "theta_df = pd.melt(theta_df, id_vars = 'period', var_name = 'parameter').assign(group = 'utility').replace({'tt': 'travel time', 'tt_sd': 'std. travel time', 's': 'intersections'})\n",
    "\n",
    "fig, axs = plot_parameters(df = theta_df, n_cols_legend = 3, figsize = (6,5.5))\n",
    "\n",
    "plt.axhline(0, linestyle ='dashed', color = 'black')\n",
    "\n",
    "plt.savefig(f'output/figures/experiments/siouxfalls-utility-periods-tvgodlulpe.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(theta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap with flows of top od pairs\n",
    "plot_top_od_flows_periods(models['tvgodlulpe'], period_keys=period_keys, period_feature=period_feature, top_k=20,\n",
    "                          historic_od=network.q.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_Q = models['tvgodlulpe'].Q.numpy()\n",
    "plot_data = pd.DataFrame()\n",
    "\n",
    "for period in range(estimated_Q.shape[0]):\n",
    "    print(f'period {period}\\n')\n",
    "    Qs = {'true': Q_true[period], 'estimated': estimated_Q[period]}  # 'historic': Q_historic,\n",
    "\n",
    "    rho_val, p = sp.stats.pearsonr(Qs[\"true\"].flatten(), Qs[\"estimated\"].flatten())\n",
    "    print(f'correlation: {rho_val}')\n",
    "\n",
    "    plot_heatmap_demands(Qs=Qs, vmin=np.min(Q_true[0]), vmax=np.max(Q_true[0]), subplots_dims=(1, len(Qs.keys())),\n",
    "                         figsize=(4*len(Qs.keys()), 4))\n",
    "    plt.show()\n",
    "\n",
    "    plot_data = pd.concat([plot_data, pd.DataFrame({'true': Qs['true'].flatten(), 'estimated':Qs['estimated'].flatten(),\n",
    "                                                    'period': period})])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4), tight_layout=True)\n",
    "sns.scatterplot(data=plot_data, x='true', y='estimated', hue = 'period', ax = ax)\n",
    "plot_annotate_r2(ax=ax, x=plot_data['true'], y=plot_data['estimated'], intercept = False, r2 = True, rho = True)\n",
    "ax.set_xlabel('true number of trips')\n",
    "ax.set_ylabel('estimated number of trips')\n",
    "ax.legend(loc='lower right', title = 'period')\n",
    "ax.set_xlim(xmin=-1e-2)\n",
    "ax.set_ylim(ymin=-1e-2)\n",
    "\n",
    "plt.savefig(f'output/figures/experiments/siouxfalls-scatter-ode-tvgodlulpe.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"theta = \"\n",
    "      f\"{dict(zip(models['tvgodlulpe'].utility.true_values.keys(), list(np.mean(models['tvgodlulpe'].theta.numpy(), axis=0))))}\")\n",
    "if models['tvgodlulpe']._kappa is not None:\n",
    "    print(f\"kappa= \"\n",
    "          f\"{dict(zip(models['tvgodlulpe'].generation.features, list(np.mean(models['tvgodlulpe'].kappa.numpy(), axis=0))))}\")\n",
    "\n",
    "print(f\"Avg abs diff of observed and estimated OD: \"\n",
    "      f\"{np.mean(np.abs(models['tvgodlulpe'].q - network.q.flatten())): 0.2f}\")\n",
    "\n",
    "print(f\"Avg observed OD: {np.mean(np.abs(network.q.flatten())): 0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = models['tvgodlulpe'].compute_loss_metrics(metrics={'mape': mape, 'mse': mse, 'r2': r2_score},\n",
    "                                                      X=XT_train, Y=YT_train).assign(dataset='training')\n",
    "\n",
    "if YT_val is not None:\n",
    "    metrics_df = pd.concat([metrics_df,\n",
    "                            models['tvgodlulpe'].compute_loss_metrics(metrics={'mape': mape, 'mse': mse, 'r2': r2_score},\n",
    "                                                                     X=XT_val, Y=YT_val).assign(dataset='validation'),\n",
    "                            compute_benchmark_metrics(metrics={'mape': mape, 'mse': mse, 'r2': r2_score}, Y_ref=YT_train,\n",
    "                                                      Y=YT_val).assign(dataset='benchmark')\n",
    "                            ])\n",
    "\n",
    "with pd.option_context('display.float_format', '{:0.2g}'.format):\n",
    "    print(pd.pivot(metrics_df, index=['component', 'dataset'], columns=['metric'])['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for period in range(n_periods):\n",
    "    print(f'period {period}\\n')\n",
    "    Qs = {'true': Q_true[period], 'tvodlulpe': models['tvodlulpe'].Q.numpy()[period], 'tvgodlulpe': models['tvgodlulpe'].Q.numpy()[period]}  # 'historic': Q_historic,\n",
    "\n",
    "    plot_heatmap_demands(Qs=Qs, vmin=np.min(Q_true[0]), vmax=np.max(Q_true[0]), subplots_dims=(1, len(Qs.keys())),\n",
    "                         figsize=(4*len(Qs.keys()), 4))\n",
    "\n",
    "    plt.savefig(f'output/figures/experiments/siouxfalls-comparison-heatmaps-ode-period-{period}.png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_N_SPLITS = 5\n",
    "_POLY_ORDER = 3\n",
    "_EPOCHS_KFOLD = _EPOCHS\n",
    "\n",
    "# Add deviation respect to historic OD matrix to improve generalization in links unseen in the training set\n",
    "_LOSS_WEIGHTS_KFOLD = {'od': 1, 'theta': 0, 'traveltime': 1, 'flow': 1, 'equilibrium': 1}\n",
    "\n",
    "_MLP_KFOLD = create_mlp_tntp(network=network, diagonal=True, homogenous=True, poly_order = _POLY_ORDER, dtype=_DTYPE, pretrain = False, link_specific = False)\n",
    "\n",
    "# It is important to initialize utility around true values, in this case we choose to initialize with the prior signs.\n",
    "_UTILITY_KFOLD = UtilityParameters(features_Y=['tt'],\n",
    "                                   features_Z=_FEATURES_Z,\n",
    "                                   initial_values={\n",
    "                                       'tt': -1, 'tt_sd': -1, 's': -1, 'psc_factor': 0,\n",
    "                                                   'fixed_effect': np.zeros_like(network.links)},\n",
    "                                   trainables={'tt': True, 'tt_sd': True, 's': True,\n",
    "                                               'psc_factor': False, 'fixed_effect': False},\n",
    "                                   time_varying=True,\n",
    "                                   dtype=_DTYPE\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_kfold = {}\n",
    "metrics_kfold = {}\n",
    "parameters_kfold = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_periods = len(np.unique(X[:, :, -1].numpy().flatten()))\n",
    "\n",
    "generated_trips = compute_generated_trips(q=tf.stack(q_true), ods=network.ods, n_nodes = len(network.nodes))\n",
    "\n",
    "print(generated_trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Comparison between MLP and BPR assuming known utility and OD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_kfold['tvlpe-mlp'] = create_model_tntp(\n",
    "    n_periods=n_periods, network=network,\n",
    "    historic_g= generated_trips,\n",
    "    performance_function = _MLP_KFOLD,\n",
    "    utility = False,\n",
    "    features_Z= _FEATURES_Z,\n",
    "    od_parameters = ODParameters(key='od',\n",
    "                             initial_values= q_true,\n",
    "                             ods=network.ods,\n",
    "                             n_nodes = len(network.nodes),\n",
    "                             n_periods=n_periods,\n",
    "                             time_varying=True,\n",
    "                             trainable=False),\n",
    "    generation = False,\n",
    ")[0]\n",
    "\n",
    "metrics_kfold['tvlpe-mlp'], parameters_kfold['tvlpe-mlp'] = train_kfold(\n",
    "    n_splits=_N_SPLITS,\n",
    "    random_state=_SEED,\n",
    "    model= models_kfold['tvlpe-mlp'],\n",
    "    X=X, Y=Y,\n",
    "    optimizers= {'learning': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['learning']),\n",
    "                 'equilibrium': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['equilibrium'])},\n",
    "    node_data=node_data,\n",
    "    loss_weights= _LOSS_WEIGHTS_KFOLD,\n",
    "    loss_metric = _LOSS_METRIC,\n",
    "    equilibrium_stage=_EQUILIBRIUM_STAGE,\n",
    "    pretrain_link_flows = True,\n",
    "    threshold_relative_gap=_RELATIVE_GAP,\n",
    "    batch_size=_BATCH_SIZE,\n",
    "    epochs_print_interval=_EPOCHS,\n",
    "    epochs= _EPOCHS_KFOLD\n",
    ")\n",
    "\n",
    "metrics_kfold['tvlpe-mlp'].to_csv(f\"./output/experiments/{datetime.now().strftime('%y%m%d%H%M%S')}_kfold_tvlpe-mlp_{network_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.2g}'.format):\n",
    "    # print(metrics_kfold_df[metrics_kfold_df.component.isin(['flow','tt'])].\\\n",
    "    #       groupby(['dataset', 'component', 'metric', 'stage'])['value'].\\\n",
    "    #       aggregate(['mean', 'std']))\n",
    "    print(metrics_kfold['tvlpe-mlp']. \\\n",
    "          groupby(['dataset', 'component', 'metric', 'stage'])['value']. \\\n",
    "          aggregate(['median', 'mean', 'std']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_metrics_kfold(df=metrics_kfold['tvlpe-mlp'][metrics_kfold['tvlpe-mlp'].component.isin(['flow', 'traveltime'])], metric_name = 'mape', showfliers = False, sharey=False)\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.set_ylim(bottom = 0)\n",
    "plt.savefig('output/figures/experiments/siouxfalls-kfold-mape-tvlpe-mlp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_kfold(df=metrics_kfold['tvlpe-mlp'][metrics_kfold['tvlpe-mlp'].component.isin(['flow', 'traveltime'])], metric_name = 'r2', showfliers = False, sharey=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_kfold['tvlpe-bpr'] = create_model_tntp(\n",
    "    n_periods=n_periods, network=network,\n",
    "    historic_g=generated_trips,\n",
    "    performance_function = create_bpr(network = network, dtype = _DTYPE),\n",
    "    utility = False,\n",
    "    features_Z=_FEATURES_Z,\n",
    "    od_parameters = ODParameters(key='od',\n",
    "                             initial_values= q_true,\n",
    "                             ods=network.ods,\n",
    "                             n_nodes = len(network.nodes),\n",
    "                             n_periods=n_periods,\n",
    "                             time_varying=True,\n",
    "                             trainable=False),\n",
    "    generation = False,\n",
    "\n",
    ")[0]\n",
    "\n",
    "\n",
    "metrics_kfold['tvlpe-bpr'], parameters_kfold['tvlpe-bpr'] = train_kfold(\n",
    "    n_splits=_N_SPLITS,\n",
    "    random_state=_SEED,\n",
    "    model= models_kfold['tvlpe-bpr'],\n",
    "    X=X, Y=Y,\n",
    "    optimizers= {'learning': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['learning']),\n",
    "               'equilibrium': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['equilibrium'])},\n",
    "    node_data=node_data,\n",
    "    loss_weights= _LOSS_WEIGHTS_KFOLD,\n",
    "    loss_metric = _LOSS_METRIC,\n",
    "    equilibrium_stage=_EQUILIBRIUM_STAGE,\n",
    "    pretrain_link_flows = True,\n",
    "    threshold_relative_gap=_RELATIVE_GAP,\n",
    "    batch_size=_BATCH_SIZE,\n",
    "    epochs_print_interval={'learning': 100, 'equilibrium': 100},\n",
    "    epochs= _EPOCHS_KFOLD\n",
    ")\n",
    "\n",
    "metrics_kfold['tvlpe-bpr'].to_csv(f\"./output/experiments/{datetime.now().strftime('%y%m%d%H%M%S')}_kfold_tvlpe-bpr_{network_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.2g}'.format):\n",
    "    # print(metrics_kfold_df[metrics_kfold_df.component.isin(['flow','tt'])].\\\n",
    "    #       groupby(['dataset', 'component', 'metric', 'stage'])['value'].\\\n",
    "    #       aggregate(['mean', 'std']))\n",
    "    print(metrics_kfold['tvlpe-bpr']. \\\n",
    "          groupby(['dataset', 'component', 'metric', 'stage'])['value']. \\\n",
    "          aggregate(['median', 'mean', 'std']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_metrics_kfold(df=metrics_kfold['tvlpe-bpr'][metrics_kfold['tvlpe-bpr'].component.isin(['flow', 'traveltime'])], metric_name = 'mape', showfliers = False, sharey=False)\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.set_ylim(bottom = 0)\n",
    "plt.savefig('output/figures/experiments/siouxfalls-kfold-mape-tvlpe-bpr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_kfold(df=metrics_kfold['tvlpe-bpr'][metrics_kfold['tvlpe-bpr'].component.isin(['flow', 'traveltime'])], metric_name = 'r2', showfliers = False, sharey=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Impact of estimating utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_kfold['tvlulpe-mlp'] = create_model_tntp(\n",
    "    n_periods=n_periods, network=network,\n",
    "    performance_function = _MLP_KFOLD,\n",
    "    utility = True,\n",
    "    utility_parameters=_UTILITY_KFOLD,\n",
    "    od_parameters = ODParameters(key='od',\n",
    "                             #initial_values= generation_factors.values[:,np.newaxis]*network.q.flatten(),\n",
    "                             initial_values= q_true,\n",
    "                             ods=network.ods,\n",
    "                             n_nodes = len(network.nodes),\n",
    "                             n_periods=n_periods,\n",
    "                             time_varying=True,\n",
    "                             trainable=False),\n",
    "    generation = False,\n",
    "      # historic_g= generated_trips,\n",
    ")[0]\n",
    "\n",
    "metrics_kfold['tvlulpe-mlp'], parameters_kfold['tvlulpe-mlp'] = train_kfold(\n",
    "    n_splits=_N_SPLITS,\n",
    "    random_state=_SEED,\n",
    "    model= models_kfold['tvlulpe-mlp'],\n",
    "    X=X, Y=Y,\n",
    "    optimizers= {'learning': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['learning']),\n",
    "                 'equilibrium': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['equilibrium'])},\n",
    "    node_data=node_data,\n",
    "    loss_weights= _LOSS_WEIGHTS_KFOLD,\n",
    "    loss_metric = _LOSS_METRIC,\n",
    "    equilibrium_stage=_EQUILIBRIUM_STAGE,\n",
    "    pretrain_link_flows = True,\n",
    "    threshold_relative_gap=_RELATIVE_GAP,\n",
    "    batch_size=_BATCH_SIZE,\n",
    "    epochs_print_interval=_EPOCHS,\n",
    "    epochs= _EPOCHS_KFOLD\n",
    ")\n",
    "\n",
    "metrics_kfold['tvlulpe-mlp'].to_csv(f\"./output/experiments/{datetime.now().strftime('%y%m%d%H%M%S')}_kfold_tvlulpe-mlp_{network_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.2g}'.format):\n",
    "    # print(metrics_kfold_df[metrics_kfold_df.component.isin(['flow','tt'])].\\\n",
    "    #       groupby(['dataset', 'component', 'metric', 'stage'])['value'].\\\n",
    "    #       aggregate(['mean', 'std']))\n",
    "    print(metrics_kfold['tvlulpe-mlp']. \\\n",
    "          groupby(['dataset', 'component', 'metric', 'stage'])['value']. \\\n",
    "          aggregate(['median', 'mean', 'std']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_metrics_kfold(df=metrics_kfold['tvlulpe-mlp'][metrics_kfold['tvlulpe-mlp'].component.isin(['flow', 'traveltime'])], metric_name = 'mape', showfliers = False, sharey=False)\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.set_ylim(bottom = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_kfold(df=metrics_kfold['tvlulpe-mlp'][metrics_kfold['tvlulpe-mlp'].component.isin(['flow', 'traveltime'])], metric_name = 'r2', showfliers = False, sharey = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_kfold['tvlulpe-mlp']['hour'] = parameters_kfold['tvlulpe-mlp'].period.replace({v: k for k, v in models_kfold['tvlulpe-mlp'].period_dict.items()}). \\\n",
    "    replace(dict(zip(period_keys.period_id, period_keys.hour)))\n",
    "\n",
    "parameters_kfold['tvlulpe-mlp']['parameter'] = parameters_kfold['tvlulpe-mlp']['parameter'].replace({'tt': 'travel time', 'tt_sd': 'std. travel time', 'vot': 'reliability ratio', 's': 'intersections'})\n",
    "\n",
    "parameters_kfold['tvlulpe-mlp'] = parameters_kfold['tvlulpe-mlp'][parameters_kfold['tvlulpe-mlp'].parameter != 'reliability ratio']\n",
    "\n",
    "fig, axs = plot_parameters_kfold(df = parameters_kfold['tvlulpe-mlp'], join=True, n_cols_legend = 3, figsize = (6,5.5))\n",
    "\n",
    "plt.axhline(0, linestyle ='dashed', color = 'black')\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-kfold-utility-periods-tvgodlulpe.png')\n",
    "\n",
    "# TODO: Add horizontal lines with the same colors for true values\n",
    "\n",
    "#parameters_kfold['tvlulpe-mlp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Effect of OD estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Traditional ODE without generation stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_kfold['tvodlulpe-mlp'] = create_model_tntp(\n",
    "    n_periods=n_periods, network=network,\n",
    "    model_key = 'tvgodlulpe',\n",
    "    performance_function= _MLP_KFOLD,\n",
    "    utility=True,\n",
    "    utility_parameters=_UTILITY_KFOLD,\n",
    "    generation=False,\n",
    "    # historic_g=generated_trips,\n",
    "    od_parameters=ODParameters(key='od',\n",
    "                               #initial_values= generation_factors.values[:,np.newaxis]*network.q.flatten(),\n",
    "                               initial_values=q_true,\n",
    "                               historic_values={0: q_historic[0], 1:q_historic[1]},\n",
    "                               ods=network.ods,\n",
    "                               n_nodes = len(network.nodes),\n",
    "                               n_periods=n_periods,\n",
    "                               time_varying=True,\n",
    "                               trainable=True),\n",
    "\n",
    ")[0]\n",
    "\n",
    "metrics_kfold['tvodlulpe-mlp'], parameters_kfold['tvodlulpe-mlp'] = train_kfold(\n",
    "    n_splits=_N_SPLITS,\n",
    "    random_state=_SEED,\n",
    "    model=models_kfold['tvodlulpe-mlp'],\n",
    "    X=X, Y=Y,\n",
    "    optimizers={'learning': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['learning']),\n",
    "                'equilibrium': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['equilibrium'])},\n",
    "    node_data=node_data,\n",
    "    loss_weights= _LOSS_WEIGHTS_KFOLD,\n",
    "    loss_metric=_LOSS_METRIC,\n",
    "    equilibrium_stage=_EQUILIBRIUM_STAGE,\n",
    "    pretrain_link_flows = True,\n",
    "    threshold_relative_gap=_RELATIVE_GAP,\n",
    "    batch_size=_BATCH_SIZE,\n",
    "    epochs_print_interval=_EPOCHS,\n",
    "    epochs=_EPOCHS_KFOLD\n",
    ")\n",
    "metrics_kfold['tvodlulpe-mlp'].to_csv(f\"./output/experiments/{datetime.now().strftime('%y%m%d%H%M%S')}_kfold_tvodlulpe-mlp_{network_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pd.option_context('display.float_format', '{:0.2g}'.format):\n",
    "    # print(metrics_kfold_df[metrics_kfold_df.component.isin(['flow','tt'])].\\\n",
    "    #       groupby(['dataset', 'component', 'metric', 'stage'])['value'].\\\n",
    "    #       aggregate(['mean', 'std']))\n",
    "    print(metrics_kfold['tvodlulpe-mlp']. \\\n",
    "          groupby(['dataset', 'component', 'metric', 'stage'])['value']. \\\n",
    "          aggregate(['median', 'mean', 'std']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_metrics_kfold(df=metrics_kfold['tvodlulpe-mlp'][metrics_kfold['tvodlulpe-mlp'].component.isin(['flow', 'traveltime'])],\n",
    "                   metric_name='mape', showfliers=False, sharey=False)\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.set_ylim(bottom = 0)\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-kfold-mape-tvodlulpe-mlp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_kfold(df=metrics_kfold['tvodlulpe-mlp'][metrics_kfold['tvodlulpe-mlp'].component.isin(['flow', 'traveltime'])],\n",
    "                   metric_name='r2', showfliers=False, sharey=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_kfold['tvodlulpe-mlp']['hour'] = parameters_kfold['tvodlulpe-mlp'].period.replace({v: k for k, v in models_kfold['tvodlulpe-mlp'].period_dict.items()}). \\\n",
    "#     replace(dict(zip(period_keys.period_id, period_keys.hour)))\n",
    "\n",
    "# parameters_kfold['tvodlulpe-mlp']['hour'] = parameters_kfold['tvodlulpe-mlp'].period.replace({v: k for k, v in models_kfold['tvodlulpe-mlp'].period_dict.items()}). \\\n",
    "#     replace(dict(zip(period_keys.period_id, period_keys.hour)))\n",
    "\n",
    "parameters_kfold['tvodlulpe-mlp']['parameter'] = parameters_kfold['tvodlulpe-mlp']['parameter'].\\\n",
    "    replace({'tt': 'travel time', 'tt_sd': 'std. travel time', 's': 'intersections', 'vot': 'reliability ratio'})\n",
    "\n",
    "parameters_kfold['tvodlulpe-mlp'] = parameters_kfold['tvodlulpe-mlp'][parameters_kfold['tvodlulpe-mlp'].parameter != 'reliability ratio']\n",
    "\n",
    "plot_parameters_kfold(df=parameters_kfold['tvodlulpe-mlp'], join=True, n_cols_legend = 3, figsize = (6,5.5))\n",
    "\n",
    "plt.axhline(0, linestyle ='dashed', color = 'black')\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-kfold-utility-periods-tvodlulpe-mlp')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameters_kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) ODE with generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_trips = compute_generated_trips(q=tf.stack(q_historic), ods=network.ods, n_nodes = len(network.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_kfold['tvgodlulpe'] = create_model_tntp(\n",
    "    n_periods=n_periods, network=network,\n",
    "    performance_function= _MLP_KFOLD,\n",
    "    utility=True,\n",
    "    utility_parameters=_UTILITY_KFOLD,\n",
    "    generation=True,\n",
    "    historic_g=generated_trips,\n",
    "    od_parameters=ODParameters(key='od',\n",
    "                           #initial_values= generation_factors.values[:,np.newaxis]*network.q.flatten(),\n",
    "                           initial_values=tf.stack(q_historic),\n",
    "                           historic_values={0: q_historic[0], 1:q_historic[1]},\n",
    "                           ods=network.ods,\n",
    "                           n_periods=n_periods,\n",
    "                           n_nodes = len(network.nodes),\n",
    "                           time_varying=True,\n",
    "                           trainable=False),\n",
    ")[0]\n",
    "\n",
    "metrics_kfold['tvgodlulpe'], parameters_kfold['tvgodlulpe'] = train_kfold(\n",
    "    n_splits=_N_SPLITS,\n",
    "    random_state=_SEED,\n",
    "    model=models_kfold['tvgodlulpe'],\n",
    "    X=X, Y=Y,\n",
    "    optimizers={'learning': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['learning']),\n",
    "                'equilibrium': tf.keras.optimizers.legacy.Adam(learning_rate=_LR['equilibrium'])},\n",
    "    node_data=node_data,\n",
    "    loss_weights= _LOSS_WEIGHTS_KFOLD,\n",
    "    loss_metric=_LOSS_METRIC,\n",
    "    equilibrium_stage=_EQUILIBRIUM_STAGE,\n",
    "    pretrain_link_flows = True,\n",
    "    threshold_relative_gap=_RELATIVE_GAP,\n",
    "    batch_size=_BATCH_SIZE,\n",
    "    epochs_print_interval=_EPOCHS,\n",
    "    epochs=_EPOCHS_KFOLD\n",
    ")\n",
    "\n",
    "metrics_kfold['tvgodlulpe'].to_csv(f\"./output/experiments/{datetime.now().strftime('%y%m%d%H%M%S')}_kfold_tvgodlulpe-mlp_{network_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.2g}'.format):\n",
    "    # print(metrics_kfold_df[metrics_kfold_df.component.isin(['flow','tt'])].\\\n",
    "    #       groupby(['dataset', 'component', 'metric', 'stage'])['value'].\\\n",
    "    #       aggregate(['mean', 'std']))\n",
    "    print(metrics_kfold['tvgodlulpe']. \\\n",
    "          groupby(['dataset', 'component', 'metric', 'stage'])['value']. \\\n",
    "          aggregate(['median', 'mean', 'std']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_metrics_kfold(df=metrics_kfold['tvgodlulpe'][metrics_kfold['tvgodlulpe'].component.isin(['flow', 'traveltime'])],\n",
    "                   metric_name='mape', showfliers=False, sharey=False)\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.set_ylim(bottom = 0)\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-kfold-mape-tvgodlulpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_kfold(df=metrics_kfold['tvgodlulpe'][metrics_kfold['tvgodlulpe'].component.isin(['flow', 'traveltime'])],\n",
    "                   metric_name='r2', showfliers=False, sharey=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_kfold['tvgodlulpe']['hour'] = parameters_kfold['tvgodlulpe'].period.replace({v: k for k, v in models_kfold['tvgodlulpe'].period_dict.items()}). \\\n",
    "    replace(dict(zip(period_keys.period_id, period_keys.hour)))\n",
    "\n",
    "parameters_kfold['tvgodlulpe']['parameter'] = parameters_kfold['tvgodlulpe']['parameter'].\\\n",
    "    replace({'tt': 'travel time', 'tt_sd': 'std. travel time', 'vot': 'reliability ratio', 's': 'intersections'})\n",
    "\n",
    "parameters_kfold['tvgodlulpe'] = parameters_kfold['tvgodlulpe'][parameters_kfold['tvgodlulpe'].parameter != 'reliability ratio']\n",
    "\n",
    "plot_parameters_kfold(df=parameters_kfold['tvgodlulpe'], join=True, n_cols_legend = 3, figsize = (6,5.5))\n",
    "\n",
    "plt.axhline(0, linestyle ='dashed', color = 'black')\n",
    "\n",
    "plt.savefig('output/figures/experiments/siouxfalls-kfold-utility-periods-tvlulpe.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_LOSS_WEIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('\\ntvgodlulpe-outofsample')\n",
    "\n",
    "n_periods = len(np.unique(XT_train[:, :, -1].numpy().flatten()))\n",
    "\n",
    "generated_trips = compute_generated_trips(q=tf.stack(q_true), ods=network.ods, n_nodes = len(network.nodes))\n",
    "\n",
    "reference_model = models['tvgodlulpe']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inference_model = create_tvgodlulpe_model_tntp(network=network, n_periods=n_periods, features_Z=_FEATURES_Z,\n",
    "                                               historic_g = generated_trips, historic_q = q_historic)\n",
    "\n",
    "inference_model.build()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inference_model.load_weights(reference_model._filepath_weights)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_ = inference_model.predict(XT_train,\n",
    "                        # period_dict = reference_model.period_dict,\n",
    "                        node_data=node_data,\n",
    "                        loss_metric=_LOSS_METRIC,\n",
    "                        # batch_size= 1,\n",
    "                        # optimizer= tf.keras.optimizers.legacy.Adam(learning_rate=_LR['equilibrium']),\n",
    "                        batch_size= None,\n",
    "                        optimizer= tf.keras.optimizers.legacy.Adam(learning_rate=1e-1),\n",
    "                        loss_weights={'equilibrium': 1},\n",
    "                        # threshold_relative_gap=5e-2,  # _RELATIVE_GAP,\n",
    "                        threshold_relative_gap=_RELATIVE_GAP,\n",
    "                        epochs_print_interval=_EPOCHS_PRINT_INTERVAL,\n",
    "                        epochs=100)\n",
    "\n",
    "with pd.option_context('display.float_format', '{:0.3g}'.format):\n",
    "    print('\\n')\n",
    "    print(inference_model.compute_loss_metrics(metrics={'mape': mape, 'mse': mse, 'r2': r2_score}, X=XT_train, Y=YT_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plot_flow_vs_traveltime(model = inference_model,\n",
    "                        observed_traveltime=inference_model.mask_observed_traveltime(YT_train[:, :, 0]),\n",
    "                        observed_flow= inference_model.mask_observed_flow(YT_train[:,:,1]),\n",
    "                        period_col = X[:,:,-1].numpy().astype(int).flatten(),\n",
    "                        all_metrics = False)\n",
    "\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.set_xlim(xmin=-10)\n",
    "    ax.set_ylim(ymin=-1)\n",
    "    ax.legend(loc='lower right', title = 'period')\n",
    "\n",
    "axs[1,1].set_xlim(xmin=-1)\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write with estimation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df, val_results_df \\\n",
    "    = map(lambda x: pd.concat([results.assign(model = model)[['model'] + list(results.columns)]\n",
    "                               for model, results in x.items()],axis = 0), [train_results_dfs, val_results_dfs])\n",
    "\n",
    "train_filename = f\"{datetime.now().strftime('%y%m%d%H%M%S')}_train_results_{network_name}.csv\"\n",
    "val_filename = f\"{datetime.now().strftime('%y%m%d%H%M%S')}_validation_results_{network_name}.csv\"\n",
    "train_results_df.to_csv(f\"./output/tables/{train_filename}\")\n",
    "print(f'File {train_filename} was written')\n",
    "val_results_df.to_csv(f\"./output/tables/{val_filename}\")\n",
    "print(f'File {val_filename} was written')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of models parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'parameter': [], 'model': []})\n",
    "\n",
    "for model_key, model in models.items():\n",
    "    model_results = {**dict(zip(['tt'] + _FEATURES_Z, list(np.mean(model.theta.numpy(), axis=0)))),\n",
    "                     **{'rr': float(model.get_parameters_estimates().eval('tt_sd/tt').iloc[0]),\n",
    "                        'fixed_effect_mean': np.mean(model.fixed_effect),\n",
    "                        'fixed_effect_std': np.std(model.fixed_effect),\n",
    "                        'od_mean': np.mean(model.q),\n",
    "                        'od_std': np.std(model.q)\n",
    "                        }}\n",
    "\n",
    "    if model.performance_function.type == 'bpr':\n",
    "        model_results = {**model_results, **{'alpha_mean': np.mean(model.performance_function.alpha),\n",
    "                                             'alpha_std': np.std(model.performance_function.alpha),\n",
    "                                             'beta_mean': np.mean(model.performance_function.beta),\n",
    "                                             'beta_std': np.std(model.performance_function.beta)}}\n",
    "\n",
    "    model_results = pd.DataFrame({'parameter': model_results.keys(), 'values': model_results.values()}). \\\n",
    "        assign(model=model_key)\n",
    "\n",
    "    results = pd.concat([results, model_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pivot_table(index = ['parameter'], columns = 'model', values = 'values', sort=False).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of models goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_losses = pd.DataFrame({})\n",
    "loss_columns = ['loss_flow', 'loss_traveltime', 'loss_equilibrium', 'loss_total']\n",
    "\n",
    "for model_key, model in models.items():\n",
    "    results_losses_model = model.split_results(train_results_dfs[model_key])[1].assign(model=model_key)\n",
    "    results_losses_model = results_losses_model[results_losses_model.epoch == _EPOCHS['learning']].iloc[[0]]\n",
    "    results_losses = pd.concat([results_losses, results_losses_model])\n",
    "\n",
    "results_losses[loss_columns] = (results_losses[loss_columns] - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_losses[['model'] + loss_columns].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of convergence toward true rr across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_estimates = {}\n",
    "train_losses = {}\n",
    "\n",
    "for model_key, model in models.items():\n",
    "    train_estimates[model_key], train_losses[model_key] = model.split_results(results=train_results_dfs[model_key])\n",
    "\n",
    "    train_estimates[model_key]['model'] = model_key\n",
    "\n",
    "train_estimates_df = pd.concat(train_estimates.values())\n",
    "\n",
    "train_estimates_df['rr'] = train_estimates_df['tt_sd'] / train_estimates_df['tt']\n",
    "\n",
    "estimates = train_estimates_df[['epoch', 'model', 'rr']].reset_index().drop('index', axis=1)\n",
    "#estimates = estimates[estimates.epoch != 0]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "g = sns.lineplot(data=estimates, x='epoch', hue='model', y='rr')\n",
    "\n",
    "utility_true_values = models['tvodlulpe'].utility.true_values\n",
    "\n",
    "ax.hlines(y=compute_rr(utility_true_values), xmin=estimates['epoch'].min(), xmax=estimates['epoch'].max(), linestyle='--', label = 'true ratio', color = 'black')\n",
    "\n",
    "ax.set_ylabel('reliability ratio')\n",
    "\n",
    "ax.set_xticks(np.arange(estimates['epoch'].min(), estimates['epoch'].max() + 1, _XTICKS_SPACING))\n",
    "\n",
    "plt.legend(loc = 'upper left')\n",
    "#ax.set_yscale('log')\n",
    "#plt.ylim(ymin=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of total trips by hour for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trips = compute_total_trips_models(models = models, period_feature = 'hour', period_keys = period_keys)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "total_trips_by_hour_models = compute_total_trips_models(models = models, period_feature = period_feature,\n",
    "                                                        period_keys = period_keys)\n",
    "\n",
    "g = sns.pointplot(data= total_trips_by_hour_models, x=period_feature, y='total_trips', ax=ax, hue='model')\n",
    "\n",
    "plt.ylabel('total trips', fontsize=12)\n",
    "\n",
    "ax.set_xticklabels([0,1])\n",
    "ax.set_xlabel('period')\n",
    "ax.legend()\n",
    "\n",
    "# plt.legend(loc='lower left')\n",
    "plt.legend(loc='upper right', title = 'model')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trips.groupby('model')[['total_trips']].mean().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trips.groupby('model')[['total_trips']].sum().round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'runtime: {time.time()-t0_global:0.1f} [s]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nesuelogit",
   "language": "python",
   "name": "nesuelogit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
